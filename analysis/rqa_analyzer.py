"""
RQA (Recurrence Quantification Analysis) åˆ†ææ¨¡å— - å¢å¼ºç‰ˆ

åŸºäºç”¨æˆ·éœ€æ±‚æ”¹è¿›ï¼Œæ”¯æŒï¼š
1. 1Dä¿¡å·åˆ†æï¼ˆä½¿ç”¨xåæ ‡ï¼‰
2. ROIä¿¡æ¯é›†æˆå’Œé¢œè‰²ç¼–ç 
3. æ”¹è¿›çš„å¯è§†åŒ–æ•ˆæœ
4. æ›´å‡†ç¡®çš„RQAæŒ‡æ ‡è®¡ç®—
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.spatial.distance import pdist, squareform
from scipy.stats import zscore
import base64
import io
import math
from typing import Dict, List, Tuple, Any
import warnings
warnings.filterwarnings('ignore')

plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

class RQAAnalyzer:
    """å¢å¼ºç‰ˆRQAåˆ†æå™¨"""
    
    def __init__(self):
        self.default_params = {
            'embedding_dimension': 2,
            'time_delay': 1,
            'recurrence_threshold': 0.05,
            'min_line_length': 2,
            'analysis_mode': '1d_x',  # '1d_x', '1d_amplitude', '2d_xy'
            'distance_metric': '1d_abs'  # '1d_abs', 'euclidean'
        }
        
        # ROIé¢œè‰²æ˜ å°„ï¼ˆåŸºäºç”¨æˆ·ä»£ç é€»è¾‘ï¼‰
        self.roi_colors = {}
        
    def analyze_data(self, data_file: str, parameters: Dict = None) -> Dict:
        """
        å¯¹çœ¼åŠ¨æ•°æ®è¿›è¡ŒRQAåˆ†æï¼ˆå¢å¼ºç‰ˆï¼‰
        
        Args:
            data_file: æ•°æ®æ–‡ä»¶è·¯å¾„
            parameters: RQAå‚æ•°
            
        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        try:
            # ä½¿ç”¨é»˜è®¤å‚æ•°å¹¶æ›´æ–°ç”¨æˆ·å‚æ•°
            params = self.default_params.copy()
            if parameters:
                params.update(parameters)
            
            # åŠ è½½æ•°æ®
            df = pd.read_csv(data_file)
            
            # æ•°æ®é¢„å¤„ç†
            signal_data, roi_info = self._preprocess_data_enhanced(df, params['analysis_mode'])
            
            # æ„å»ºåµŒå…¥ç©ºé—´
            embedded_data = self._embed_signal(signal_data, 
                                             params['embedding_dimension'], 
                                             params['time_delay'])
            
            # è®¡ç®—é€’å½’çŸ©é˜µ
            recurrence_matrix = self._compute_recurrence_matrix_enhanced(
                embedded_data, 
                params['recurrence_threshold'],
                params['distance_metric']
            )
            
            # ç”Ÿæˆé€’å½’å›¾ï¼ˆå¢å¼ºç‰ˆï¼ŒåŒ…å«ROIä¿¡æ¯ï¼‰
            recurrence_plot = self._create_enhanced_recurrence_plot(
                recurrence_matrix, df, roi_info, params
            )
            
            # è®¡ç®—RQAæŒ‡æ ‡
            metrics = self._compute_rqa_metrics_enhanced(
                recurrence_matrix, 
                params['min_line_length']
            )
            
            # ç”Ÿæˆæ—¶é—´åºåˆ—å›¾
            time_series_plot = self._create_time_series_plot(
                signal_data, df, roi_info, params
            )
            
            return {
                'success': True,
                'recurrence_plot': recurrence_plot,
                'time_series_plot': time_series_plot,
                'metrics': metrics,
                'parameters': params,
                'analysis_info': {
                    'data_points': int(len(df)),
                    'embedding_points': int(len(embedded_data)),
                    'analysis_mode': str(params['analysis_mode']),
                    'roi_count': int(len(roi_info['unique_rois']) if roi_info else 0)
                }
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }
    
    def _preprocess_data_enhanced(self, df: pd.DataFrame, analysis_mode: str) -> Tuple[np.ndarray, Dict]:
        """å¢å¼ºæ•°æ®é¢„å¤„ç†"""
        # æ£€æŸ¥å¿…è¦çš„åˆ—
        required_cols = ['x']
        if analysis_mode == '2d_xy':
            required_cols.append('y')
        
        missing_cols = [col for col in required_cols if col not in df.columns]
        if missing_cols:
            raise ValueError(f"æ•°æ®æ–‡ä»¶ç¼ºå°‘åˆ—: {missing_cols}")
        
        # æå–ä¿¡å·æ•°æ®
        if analysis_mode == '1d_x':
            # ä½¿ç”¨xåæ ‡ä½œä¸º1Dä¿¡å·
            signal_data = df['x'].values
        elif analysis_mode == '1d_amplitude':
            # ä½¿ç”¨å¹…åº¦ sqrt(x^2 + y^2)
            x_vals = df['x'].values
            y_vals = df['y'].values if 'y' in df.columns else np.zeros_like(x_vals)
            signal_data = np.sqrt(x_vals**2 + y_vals**2)
        elif analysis_mode == '2d_xy':
            # ä½¿ç”¨x,yåæ ‡
            signal_data = np.column_stack([df['x'].values, df['y'].values])
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„åˆ†ææ¨¡å¼: {analysis_mode}")
        
        # å¤„ç†ROIä¿¡æ¯
        roi_info = self._extract_roi_info(df)
        
        # å»é™¤æ— æ•ˆå€¼
        if signal_data.ndim == 1:
            valid_mask = ~np.isnan(signal_data)
            signal_data = signal_data[valid_mask]
        else:
            valid_mask = ~(np.isnan(signal_data).any(axis=1))
            signal_data = signal_data[valid_mask]
        
        return signal_data, roi_info
    
    def _extract_roi_info(self, df: pd.DataFrame) -> Dict:
        """æå–ROIä¿¡æ¯"""
        roi_info = {
            'rois': [],
            'sequences': [],
            'unique_rois': [],
            'roi_colors': {}
        }
        
        if 'ROI' in df.columns and 'SequenceID' in df.columns:
            # æ¸…ç†ROIåç§°ï¼ˆå»é™¤n2å‰ç¼€ï¼‰
            df_roi = df['ROI'].fillna('Unknown').astype(str)
            df_roi_cleaned = df_roi.str.replace('n2', '', regex=False)
            
            roi_info['rois'] = df_roi_cleaned.values
            roi_info['sequences'] = df['SequenceID'].values
            roi_info['unique_rois'] = sorted(df_roi_cleaned.unique())
            
            # åˆ†é…é¢œè‰²
            cmap = plt.cm.get_cmap('tab20', len(roi_info['unique_rois']))
            for i, roi in enumerate(roi_info['unique_rois']):
                roi_info['roi_colors'][roi] = cmap(i)
        else:
            # ä¸ºç¼ºå°‘ROI/SequenceIDä¿¡æ¯çš„æ•°æ®ç”Ÿæˆé»˜è®¤å€¼
            print("è­¦å‘Š: æ•°æ®ä¸­ç¼ºå°‘ROIæˆ–SequenceIDåˆ—ï¼Œä½¿ç”¨é»˜è®¤å€¼")
            n_points = len(df)
            roi_info['rois'] = ['background'] * n_points
            roi_info['sequences'] = [0] * n_points
            roi_info['unique_rois'] = ['background']
            roi_info['roi_colors'] = {'background': plt.cm.tab20(0)}
        
        return roi_info
    
    def _embed_signal(self, signal_data: np.ndarray, m: int, delay: int) -> np.ndarray:
        """ä¿¡å·åµŒå…¥"""
        if signal_data.ndim == 1:
            # 1Dä¿¡å·åµŒå…¥
            N = len(signal_data)
            rows = N - (m-1)*delay
            if rows <= 0:
                return np.empty((0, m))
            
            embedded = np.zeros((rows, m))
            for i in range(rows):
                for j in range(m):
                    embedded[i, j] = signal_data[i + j*delay]
            return embedded
        else:
            # 2Dä¿¡å·åµŒå…¥
            N = signal_data.shape[0]
            rows = N - (m-1)*delay
            if rows <= 0:
                return np.empty((0, m*2))
            
            embedded = np.zeros((rows, m*2))
            for i in range(rows):
                for j in range(m):
                    embedded[i, j*2] = signal_data[i + j*delay, 0]
                    embedded[i, j*2+1] = signal_data[i + j*delay, 1]
            return embedded
    
    def _compute_recurrence_matrix_enhanced(self, embedded_data: np.ndarray, 
                                          threshold: float, metric: str) -> np.ndarray:
        """è®¡ç®—é€’å½’çŸ©é˜µï¼ˆå¢å¼ºç‰ˆï¼‰"""
        M = embedded_data.shape[0]
        RP = np.zeros((M, M), dtype=int)
        
        for i in range(M):
            for j in range(M):
                if metric == '1d_abs':
                    # 1Dç»å¯¹å·®è·ç¦»
                    dist = np.sum(np.abs(embedded_data[i] - embedded_data[j]))
                elif metric == 'euclidean':
                    # æ¬§å‡ é‡Œå¾—è·ç¦»
                    dist = np.sqrt(np.sum((embedded_data[i] - embedded_data[j])**2))
                else:
                    dist = 0
                
                if dist <= threshold:
                    RP[i, j] = 1
        
        return RP
    
    def _create_enhanced_recurrence_plot(self, recurrence_matrix: np.ndarray, 
                                       df: pd.DataFrame, roi_info: Dict, 
                                       params: Dict) -> str:
        """åˆ›å»ºå¢å¼ºé€’å½’å›¾"""
        fig, ax = plt.subplots(figsize=(10, 10))
        
        # æ˜¾ç¤ºé€’å½’çŸ©é˜µ
        ax.imshow(recurrence_matrix, cmap='binary', origin='lower')
        ax.set_title(f'é€’å½’å›¾ (Recurrence Plot) - {params["analysis_mode"]}', 
                    fontsize=14, fontweight='bold')
        ax.set_xlabel('æ—¶é—´ç´¢å¼•', fontsize=12)
        ax.set_ylabel('æ—¶é—´ç´¢å¼•', fontsize=12)
        
        # æ·»åŠ ROIä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
        if roi_info and 'sequences' in roi_info:
            self._add_roi_rectangles_to_rp(ax, df, roi_info, recurrence_matrix.shape[0])
        
        # ä¿å­˜ä¸ºbase64
        buffer = io.BytesIO()
        plt.savefig(buffer, format='png', dpi=150, bbox_inches='tight')
        buffer.seek(0)
        plot_data = base64.b64encode(buffer.getvalue()).decode()
        plt.close()
        
        return plot_data
    
    def _add_roi_rectangles_to_rp(self, ax, df: pd.DataFrame, roi_info: Dict, matrix_size: int):
        """åœ¨é€’å½’å›¾ä¸Šæ·»åŠ ROIçŸ©å½¢"""
        from matplotlib.patches import Rectangle
        
        # æ£€æŸ¥æ˜¯å¦æœ‰SequenceIDåˆ—
        if 'SequenceID' not in df.columns:
            # å¦‚æœæ²¡æœ‰SequenceIDåˆ—ï¼Œç›´æ¥è¿”å›ï¼Œä¸æ·»åŠ ROIçŸ©å½¢
            return
        
        # è·å–åºåˆ—ä¿¡æ¯
        seq_vals = df['SequenceID'].unique()
        
        for sid in sorted(seq_vals):
            if sid <= 0:
                continue
            
            # æ‰¾åˆ°è¯¥åºåˆ—çš„ç´¢å¼•èŒƒå›´
            inds = df.index[df['SequenceID'] == sid].to_numpy()
            if len(inds) < 2:
                continue
            
            st_i = inds[0]
            ed_i = inds[-1]
            
            # ç¡®ä¿ç´¢å¼•åœ¨çŸ©é˜µèŒƒå›´å†…
            if st_i >= matrix_size:
                continue
            if ed_i >= matrix_size:
                ed_i = matrix_size - 1
            
            w = ed_i - st_i + 1
            if w < 1:
                continue
            
            # è·å–ROIä¿¡æ¯
            roi_name = roi_info['rois'][st_i] if st_i < len(roi_info['rois']) else 'Unknown'
            color = roi_info['roi_colors'].get(roi_name, 'gray')
            
            # åœ¨å¯¹è§’çº¿ä½ç½®ç»˜åˆ¶çŸ©å½¢
            rect = Rectangle((st_i, st_i), w, w,
                           fill=True, alpha=0.3, color=color, linewidth=1)
            ax.add_patch(rect)
            
            # æ·»åŠ æ ‡ç­¾
            cx = st_i + w/2
            ax.text(cx, cx, f'S{sid}({roi_name})', 
                   color='black', fontsize=8, ha='center', va='center',
                   bbox=dict(boxstyle="round,pad=0.2", facecolor='white', alpha=0.7))
    
    def _create_time_series_plot(self, signal_data: np.ndarray, 
                               df: pd.DataFrame, roi_info: Dict, 
                               params: Dict) -> str:
        """åˆ›å»ºæ—¶é—´åºåˆ—å›¾"""
        fig, ax = plt.subplots(figsize=(12, 6))
        
        # æ—¶é—´è½´
        if 'milliseconds' in df.columns:
            time_vals = df['milliseconds'].values[:len(signal_data)]
            ax.set_xlabel('æ—¶é—´ (ms)', fontsize=12)
        else:
            time_vals = np.arange(len(signal_data))
            ax.set_xlabel('æ—¶é—´ç´¢å¼•', fontsize=12)
        
        # ç»˜åˆ¶ä¿¡å·
        if signal_data.ndim == 1:
            ax.plot(time_vals, signal_data, color='blue', linewidth=1.2, alpha=0.8)
            ax.set_ylabel(f'ä¿¡å·å€¼ ({params["analysis_mode"]})', fontsize=12)
        else:
            ax.plot(time_vals, signal_data[:, 0], label='X', color='blue', linewidth=1.2)
            ax.plot(time_vals, signal_data[:, 1], label='Y', color='red', linewidth=1.2)
            ax.legend()
            ax.set_ylabel('åæ ‡å€¼', fontsize=12)
        
        # æ·»åŠ ROIé¢œè‰²å¡«å……
        if roi_info and 'sequences' in roi_info:
            self._add_roi_coloring_to_timeseries(ax, df, roi_info, time_vals, signal_data)
        
        ax.set_title(f'æ—¶é—´åºåˆ— - {params["analysis_mode"]}', fontsize=14, fontweight='bold')
        ax.grid(True, alpha=0.3)
        
        # ä¿å­˜ä¸ºbase64
        buffer = io.BytesIO()
        plt.savefig(buffer, format='png', dpi=150, bbox_inches='tight')
        buffer.seek(0)
        plot_data = base64.b64encode(buffer.getvalue()).decode()
        plt.close()
        
        return plot_data
    
    def _add_roi_coloring_to_timeseries(self, ax, df: pd.DataFrame, roi_info: Dict, 
                                      time_vals: np.ndarray, signal_data: np.ndarray):
        """ä¸ºæ—¶é—´åºåˆ—æ·»åŠ ROIé¢œè‰²"""
        # æ£€æŸ¥æ˜¯å¦æœ‰SequenceIDåˆ—
        if 'SequenceID' not in df.columns:
            # å¦‚æœæ²¡æœ‰SequenceIDåˆ—ï¼Œç›´æ¥è¿”å›ï¼Œä¸æ·»åŠ ROIé¢œè‰²
            return
            
        seq_vals = df['SequenceID'].unique()
        
        for sid in sorted(seq_vals):
            if sid <= 0:
                continue
            
            inds = df.index[df['SequenceID'] == sid].to_numpy()
            if len(inds) < 2:
                continue
            
            st_i = inds[0]
            ed_i = min(inds[-1], len(signal_data) - 1)
            
            if st_i >= len(signal_data):
                continue
            
            # è·å–è¯¥æ®µçš„æ—¶é—´å’Œä¿¡å·å€¼
            seg_time = time_vals[st_i:ed_i+1]
            
            if signal_data.ndim == 1:
                seg_signal = signal_data[st_i:ed_i+1]
                roi_name = roi_info['rois'][st_i] if st_i < len(roi_info['rois']) else 'Unknown'
                color = roi_info['roi_colors'].get(roi_name, 'gray')
                
                # å¡«å……åˆ°0çº¿
                ax.fill_between(seg_time, seg_signal, 0, color=color, alpha=0.3)
                
                # æ·»åŠ ROIæ ‡ç­¾
                if len(seg_time) > 0 and len(seg_signal) > 0:
                    ax.text(seg_time[0], seg_signal[0], f'S{sid}({roi_name})',
                           color=color, fontsize=8, ha='right', va='top',
                           bbox=dict(boxstyle="round,pad=0.2", facecolor='white', alpha=0.7))
    
    def _compute_rqa_metrics_enhanced(self, recurrence_matrix: np.ndarray, 
                                    min_line_length: int) -> Dict:
        """è®¡ç®—RQAæŒ‡æ ‡ï¼ˆå¢å¼ºç‰ˆï¼‰"""
        N = recurrence_matrix.shape[0]
        
        # é€’å½’ç‡ (Recurrence Rate, RR)
        total_points = N * N
        recurrent_points = np.sum(recurrence_matrix)
        RR = recurrent_points / total_points
        
        # æå–å¯¹è§’çº¿æ®µé•¿åº¦
        diag_lengths = self._extract_diagonal_lengths_enhanced(recurrence_matrix)
        
        # ç¡®å®šæ€§ (Determinism, DET)
        total_diag_points = sum(length * count for length, count in diag_lengths.items())
        long_diag_points = sum(length * count for length, count in diag_lengths.items() 
                              if length >= min_line_length)
        DET = long_diag_points / total_diag_points if total_diag_points > 0 else 0
        
        # å¹³å‡å¯¹è§’çº¿é•¿åº¦ (L)
        if long_diag_points > 0:
            weighted_lengths = [length for length, count in diag_lengths.items() 
                              if length >= min_line_length for _ in range(count)]
            L = np.mean(weighted_lengths) if weighted_lengths else 0
        else:
            L = 0
        
        # æœ€å¤§å¯¹è§’çº¿é•¿åº¦ (Lmax)
        long_lengths = [length for length in diag_lengths.keys() if length >= min_line_length]
        Lmax = max(long_lengths) if long_lengths else 0
        
        # å‘æ•£æ€§ (Divergence, DIV)
        DIV = 1.0 / Lmax if Lmax > 0 else 0
        
        # å±‚æµæ€§ (Laminarity, LAM) - åŸºäºå‚ç›´çº¿ç»“æ„
        vert_lengths = self._extract_vertical_lengths_enhanced(recurrence_matrix)
        total_vert_points = sum(length * count for length, count in vert_lengths.items())
        long_vert_points = sum(length * count for length, count in vert_lengths.items() 
                              if length >= min_line_length)
        LAM = long_vert_points / total_vert_points if total_vert_points > 0 else 0
        
        # å¹³å‡å‚ç›´çº¿é•¿åº¦ (TT)
        if long_vert_points > 0:
            weighted_vert_lengths = [length for length, count in vert_lengths.items() 
                                   if length >= min_line_length for _ in range(count)]
            TT = np.mean(weighted_vert_lengths) if weighted_vert_lengths else 0
        else:
            TT = 0
        
        # æœ€å¤§å‚ç›´çº¿é•¿åº¦ (Vmax)
        long_vert_lengths = [length for length in vert_lengths.keys() if length >= min_line_length]
        Vmax = max(long_vert_lengths) if long_vert_lengths else 0
        
        # ç†µ (Entropy, ENTR)
        ENTR = self._compute_shannon_entropy(diag_lengths, min_line_length)
        
        # ç¡®ä¿æ‰€æœ‰å€¼éƒ½æ˜¯JSONå¯åºåˆ—åŒ–çš„PythonåŸç”Ÿç±»å‹
        return {
            'RR': float(round(RR, 6)),
            'DET': float(round(DET, 6)),
            'LAM': float(round(LAM, 6)),
            'L': float(round(L, 4)),
            'Lmax': int(Lmax),
            'DIV': float(round(DIV, 6)),
            'TT': float(round(TT, 4)),
            'Vmax': int(Vmax),
            'ENTR': float(round(ENTR, 6))
        }
    
    def _extract_diagonal_lengths_enhanced(self, matrix: np.ndarray) -> Dict[int, int]:
        """æå–å¯¹è§’çº¿é•¿åº¦ï¼ˆå¢å¼ºç‰ˆï¼‰"""
        lengths = {}
        N = matrix.shape[0]
        
        # éå†æ‰€æœ‰å¯¹è§’çº¿ï¼ˆä¸»å¯¹è§’çº¿åŠå…¶å¹³è¡Œçº¿ï¼‰
        for offset in range(-(N-1), N):
            diagonal = np.diagonal(matrix, offset=offset)
            current_length = 0
            
            for point in diagonal:
                if point == 1:
                    current_length += 1
                else:
                    if current_length > 0:
                        lengths[current_length] = lengths.get(current_length, 0) + 1
                    current_length = 0
            
            # å¤„ç†å¯¹è§’çº¿æœ«å°¾
            if current_length > 0:
                lengths[current_length] = lengths.get(current_length, 0) + 1
        
        return lengths
    
    def _extract_vertical_lengths_enhanced(self, matrix: np.ndarray) -> Dict[int, int]:
        """æå–å‚ç›´çº¿é•¿åº¦ï¼ˆå¢å¼ºç‰ˆï¼‰"""
        lengths = {}
        N = matrix.shape[0]
        
        # éå†æ‰€æœ‰åˆ—
        for col in range(N):
            current_length = 0
            
            for row in range(N):
                if matrix[row, col] == 1:
                    current_length += 1
                else:
                    if current_length > 0:
                        lengths[current_length] = lengths.get(current_length, 0) + 1
                    current_length = 0
            
            # å¤„ç†åˆ—æœ«å°¾
            if current_length > 0:
                lengths[current_length] = lengths.get(current_length, 0) + 1
        
        return lengths
    
    def _compute_shannon_entropy(self, length_dict: Dict[int, int], min_length: int) -> float:
        """è®¡ç®—Shannonç†µ"""
        # åªè€ƒè™‘é•¿åº¦ >= min_length çš„çº¿æ®µ
        relevant_lengths = {length: count for length, count in length_dict.items() 
                          if length >= min_length}
        
        if not relevant_lengths:
            return 0.0
        
        total_count = sum(relevant_lengths.values())
        if total_count == 0:
            return 0.0
        
        entropy = 0.0
        for count in relevant_lengths.values():
            probability = count / total_count
            if probability > 1e-12:
                entropy -= probability * math.log2(probability)
        
        return entropy
    
    def compare_groups(self, results_list: List[Dict]) -> Dict:
        """æ¯”è¾ƒå¤šç»„RQAç»“æœ"""
        if len(results_list) < 2:
            return {'error': 'éœ€è¦è‡³å°‘ä¸¤ç»„æ•°æ®è¿›è¡Œæ¯”è¾ƒ'}
        
        # æå–æŒ‡æ ‡
        metrics_names = ['RR', 'DET', 'LAM', 'L', 'Lmax', 'DIV', 'TT', 'Vmax', 'ENTR']
        comparison = {}
        
        for metric in metrics_names:
            values = [result['metrics'][metric] for result in results_list 
                     if 'metrics' in result and metric in result['metrics']]
            
            if values:
                # ç¡®ä¿æ‰€æœ‰ç»Ÿè®¡å€¼éƒ½æ˜¯JSONå¯åºåˆ—åŒ–çš„PythonåŸç”Ÿç±»å‹
                comparison[metric] = {
                    'mean': float(np.mean(values)),
                    'std': float(np.std(values)),
                    'min': float(np.min(values)),
                    'max': float(np.max(values)),
                    'values': [float(v) if isinstance(v, (np.integer, np.floating)) else v for v in values]
                }
        
        return comparison


def create_rqa_analyzer():
    """åˆ›å»ºRQAåˆ†æå™¨å®ä¾‹"""
    return RQAAnalyzer()


# æµ‹è¯•å‡½æ•°
if __name__ == "__main__":
    analyzer = create_rqa_analyzer()
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®ï¼ˆæ¨¡æ‹Ÿçœ¼åŠ¨æ•°æ®ï¼‰
    np.random.seed(42)
    n_points = 500
    
    # æ¨¡æ‹Ÿxåæ ‡æ•°æ®ï¼ˆå¸¦æœ‰ä¸€äº›å‘¨æœŸæ€§æ¨¡å¼ï¼‰
    t = np.linspace(0, 10, n_points)
    x = 5 * np.sin(0.5 * t) + 2 * np.cos(2 * t) + 0.5 * np.random.randn(n_points)
    y = 3 * np.cos(0.3 * t) + 1.5 * np.sin(1.5 * t) + 0.5 * np.random.randn(n_points)
    
    # æ¨¡æ‹ŸROIå’Œåºåˆ—ä¿¡æ¯
    roi_names = ['ROI_A', 'ROI_B', 'ROI_C'] * (n_points // 100 + 1)
    sequence_ids = np.repeat(range(1, n_points // 100 + 2), 100)[:n_points]
    
    test_df = pd.DataFrame({
        'x': x,
        'y': y,
        'ROI': roi_names[:n_points],
        'SequenceID': sequence_ids,
        'milliseconds': np.arange(n_points) * 16.67  # æ¨¡æ‹Ÿ60Hzé‡‡æ ·
    })
    
    # ä¿å­˜æµ‹è¯•æ•°æ®
    test_file = 'test_rqa_enhanced_data.csv'
    test_df.to_csv(test_file, index=False)
    
    # è¿è¡Œåˆ†æ
    params = {
        'analysis_mode': '1d_x',
        'embedding_dimension': 2,
        'time_delay': 1,
        'recurrence_threshold': 0.1,
        'min_line_length': 2,
        'distance_metric': '1d_abs'
    }
    
    result = analyzer.analyze_data(test_file, params)
    
    if result['success']:
        print("ğŸ‰ RQAåˆ†ææˆåŠŸ!")
        print("ğŸ“Š æŒ‡æ ‡:")
        for key, value in result['metrics'].items():
            print(f"  {key}: {value}")
        print(f"\nğŸ“ˆ æ•°æ®ä¿¡æ¯:")
        for key, value in result['data_info'].items():
            print(f"  {key}: {value}")
    else:
        print(f"âŒ åˆ†æå¤±è´¥: {result['error']}") 