#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®èŒƒå›´åˆ†æå™¨ - åˆ†æå„æŒ‡æ ‡çš„æ•°å€¼èŒƒå›´ä»¥è®¾è®¡å½’ä¸€åŒ–æ–¹æ¡ˆ
"""

import pandas as pd
import numpy as np
import os
import glob
from typing import Dict, List, Tuple
import json

class DataRangeAnalyzer:
    """æ•°æ®èŒƒå›´åˆ†æå™¨"""
    
    def __init__(self, data_root: str = "data"):
        self.data_root = data_root
        self.stats = {}
        
    def analyze_game_duration(self) -> Dict:
        """åˆ†ææ¸¸æˆæ€»æ—¶é•¿"""
        print("ğŸ“Š åˆ†ææ¸¸æˆæ€»æ—¶é•¿...")
        
        durations = []
        groups = ['ad_calibrated', 'mci_calibrated', 'control_calibrated']
        
        for group in groups:
            group_path = os.path.join(self.data_root, group)
            if not os.path.exists(group_path):
                continue
                
            # éå†æ‰€æœ‰ç»„æ–‡ä»¶å¤¹
            for group_folder in os.listdir(group_path):
                folder_path = os.path.join(group_path, group_folder)
                if not os.path.isdir(folder_path):
                    continue
                    
                # éå†æ¯ä¸ªæ–‡ä»¶
                for file in os.listdir(folder_path):
                    if file.endswith('_preprocessed_calibrated.csv'):
                        file_path = os.path.join(folder_path, file)
                        try:
                            df = pd.read_csv(file_path)
                            if 'milliseconds' in df.columns and len(df) > 0:
                                duration_ms = df['milliseconds'].max() - df['milliseconds'].min()
                                duration_s = duration_ms / 1000.0
                                durations.append(duration_s)
                                print(f"  {file}: {duration_s:.2f}s")
                        except Exception as e:
                            print(f"  âŒ æ— æ³•è¯»å– {file}: {e}")
        
        if durations:
            stats = {
                'count': len(durations),
                'min': min(durations),
                'max': max(durations), 
                'mean': np.mean(durations),
                'std': np.std(durations),
                'median': np.median(durations),
                'q25': np.percentile(durations, 25),
                'q75': np.percentile(durations, 75)
            }
        else:
            stats = {'error': 'æœªæ‰¾åˆ°æœ‰æ•ˆçš„æ—¶é•¿æ•°æ®'}
            
        self.stats['game_duration'] = stats
        return stats
    
    def analyze_roi_fixation_time(self) -> Dict:
        """åˆ†æROIæ³¨è§†æ—¶é—´"""
        print("ğŸ“Š åˆ†æROIæ³¨è§†æ—¶é—´...")
        
        roi_file = os.path.join(self.data_root, 'event_analysis_results', 'All_ROI_Summary.csv')
        if not os.path.exists(roi_file):
            return {'error': f'æ–‡ä»¶ä¸å­˜åœ¨: {roi_file}'}
        
        try:
            df = pd.read_csv(roi_file)
            
            # åˆ†æFixTimeåˆ—
            fix_times = df['FixTime'].dropna()
            
            # æŒ‰ä»»åŠ¡åˆ†ç»„åˆ†æ
            task_stats = {}
            for i in range(1, 6):  # Q1-Q5
                task_data = df[df['ADQ_ID'].str.contains(f'q{i}', na=False)]['FixTime'].dropna()
                if len(task_data) > 0:
                    task_stats[f'Q{i}'] = {
                        'count': len(task_data),
                        'min': task_data.min(),
                        'max': task_data.max(),
                        'mean': task_data.mean(),
                        'std': task_data.std(),
                        'median': task_data.median()
                    }
            
            # æŒ‰ROIç±»å‹åˆ†æ
            roi_type_stats = {}
            for roi_type in ['KW', 'INST', 'BG']:
                roi_data = df[df['ROI'].str.contains(roi_type, na=False)]['FixTime'].dropna()
                if len(roi_data) > 0:
                    roi_type_stats[roi_type] = {
                        'count': len(roi_data),
                        'min': roi_data.min(),
                        'max': roi_data.max(),
                        'mean': roi_data.mean(),
                        'std': roi_data.std(),
                        'median': roi_data.median()
                    }
            
            overall_stats = {
                'overall': {
                    'count': len(fix_times),
                    'min': fix_times.min(),
                    'max': fix_times.max(),
                    'mean': fix_times.mean(),
                    'std': fix_times.std(),
                    'median': fix_times.median(),
                    'q25': np.percentile(fix_times, 25),
                    'q75': np.percentile(fix_times, 75),
                    'q95': np.percentile(fix_times, 95),
                    'q99': np.percentile(fix_times, 99)
                },
                'by_task': task_stats,
                'by_roi_type': roi_type_stats
            }
            
        except Exception as e:
            overall_stats = {'error': f'åˆ†æROIæ•°æ®å¤±è´¥: {e}'}
        
        self.stats['roi_fixation_time'] = overall_stats
        return overall_stats
    
    def analyze_rqa_metrics(self) -> Dict:
        """åˆ†æRQAæŒ‡æ ‡"""
        print("ğŸ“Š åˆ†æRQAæŒ‡æ ‡...")
        
        rqa_path = os.path.join(self.data_root, 'rqa_pipeline_results', 'm2_tau1_eps0.055_lmin2', 'step1_rqa_calculation')
        if not os.path.exists(rqa_path):
            return {'error': f'RQAè·¯å¾„ä¸å­˜åœ¨: {rqa_path}'}
        
        rqa_metrics = ['RR-2D-xy', 'RR-1D-x', 'DET-2D-xy', 'DET-1D-x', 'ENT-2D-xy', 'ENT-1D-x']
        all_stats = {}
        
        # è¯»å–æ‰€æœ‰RQAæ–‡ä»¶
        all_data = []
        for group in ['ad', 'control', 'mci']:
            file_path = os.path.join(rqa_path, f'RQA_1D2D_summary_{group}.csv')
            if os.path.exists(file_path):
                try:
                    df = pd.read_csv(file_path)
                    df['group'] = group
                    all_data.append(df)
                except Exception as e:
                    print(f"  âŒ æ— æ³•è¯»å– {file_path}: {e}")
        
        if not all_data:
            return {'error': 'æœªæ‰¾åˆ°æœ‰æ•ˆçš„RQAæ•°æ®'}
        
        # åˆå¹¶æ‰€æœ‰æ•°æ®
        combined_df = pd.concat(all_data, ignore_index=True)
        
        # åˆ†ææ¯ä¸ªæŒ‡æ ‡
        for metric in rqa_metrics:
            if metric in combined_df.columns:
                values = combined_df[metric].dropna()
                if len(values) > 0:
                    # æŒ‰ä»»åŠ¡åˆ†ç»„
                    task_stats = {}
                    for q in range(1, 6):
                        task_data = combined_df[combined_df['q'] == q][metric].dropna()
                        if len(task_data) > 0:
                            task_stats[f'Q{q}'] = {
                                'count': len(task_data),
                                'min': task_data.min(),
                                'max': task_data.max(),
                                'mean': task_data.mean(),
                                'std': task_data.std(),
                                'median': task_data.median()
                            }
                    
                    # æŒ‰ç»„åˆ†ç»„
                    group_stats = {}
                    for group in ['ad', 'control', 'mci']:
                        group_data = combined_df[combined_df['group'] == group][metric].dropna()
                        if len(group_data) > 0:
                            group_stats[group] = {
                                'count': len(group_data),
                                'min': group_data.min(),
                                'max': group_data.max(),
                                'mean': group_data.mean(),
                                'std': group_data.std(),
                                'median': group_data.median()
                            }
                    
                    all_stats[metric] = {
                        'overall': {
                            'count': len(values),
                            'min': values.min(),
                            'max': values.max(),
                            'mean': values.mean(),
                            'std': values.std(),
                            'median': values.median(),
                            'q25': np.percentile(values, 25),
                            'q75': np.percentile(values, 75),
                            'q95': np.percentile(values, 95),
                            'q99': np.percentile(values, 99)
                        },
                        'by_task': task_stats,
                        'by_group': group_stats
                    }
        
        self.stats['rqa_metrics'] = all_stats
        return all_stats
    
    def calculate_roi_time_percentage(self) -> Dict:
        """è®¡ç®—ROIæ—¶é—´å æ¯”çš„ç†è®ºèŒƒå›´"""
        print("ğŸ“Š åˆ†æROIæ—¶é—´å æ¯”...")
        
        # åŸºäºå·²æœ‰æ•°æ®ä¼°ç®—
        roi_stats = self.stats.get('roi_fixation_time', {})
        duration_stats = self.stats.get('game_duration', {})
        
        if not roi_stats or not duration_stats:
            return {'error': 'éœ€è¦å…ˆåˆ†æROIæ—¶é—´å’Œæ¸¸æˆæ—¶é•¿'}
        
        # ROIæ—¶é—´å æ¯” = ROIæ³¨è§†æ—¶é—´ / æ€»æ¸¸æˆæ—¶é—´
        # ç†è®ºæœ€å°å€¼ï¼š0% (æ²¡æœ‰æ³¨è§†ROI)
        # ç†è®ºæœ€å¤§å€¼ï¼š100% (å…¨ç¨‹éƒ½åœ¨æ³¨è§†åŒä¸€ä¸ªROIï¼Œä¸ç°å®)
        # å®é™…æœ€å¤§å€¼ï¼šé€šå¸¸ä¸è¶…è¿‡80-90%
        
        roi_min = roi_stats['overall']['min']
        roi_max = roi_stats['overall']['max']
        duration_min = duration_stats['min']
        duration_max = duration_stats['max']
        
        # è®¡ç®—å¯èƒ½çš„å æ¯”èŒƒå›´
        percentage_stats = {
            'theoretical_min': 0.0,  # 0%
            'theoretical_max': 1.0,  # 100%
            'practical_min': roi_min / duration_max,  # æœ€å°ROIæ—¶é—´ / æœ€å¤§æ¸¸æˆæ—¶é—´
            'practical_max': roi_max / duration_min,  # æœ€å¤§ROIæ—¶é—´ / æœ€å°æ¸¸æˆæ—¶é—´
            'estimated_typical_max': 0.8,  # å…¸å‹æœ€å¤§å€¼80%
            'note': 'ROIæ—¶é—´å æ¯” = ROIæ³¨è§†æ—¶é—´ / æ€»æ¸¸æˆæ—¶é—´'
        }
        
        self.stats['roi_time_percentage'] = percentage_stats
        return percentage_stats
    
    def generate_normalization_config(self) -> Dict:
        """ç”Ÿæˆå½’ä¸€åŒ–é…ç½®"""
        print("ğŸ“Š ç”Ÿæˆå½’ä¸€åŒ–é…ç½®...")
        
        config = {
            'version': '1.0',
            'description': 'çœ¼åŠ¨æ•°æ®å½’ä¸€åŒ–é…ç½®',
            'features': {}
        }
        
        # æ¸¸æˆæ€»æ—¶é•¿å½’ä¸€åŒ– (0-180ç§’ -> 0-1)
        config['features']['game_duration'] = {
            'name': 'æ¸¸æˆæ€»æ—¶é•¿',
            'unit': 'ç§’',
            'min_value': 0.0,
            'max_value': 180.0,  # 3åˆ†é’Ÿ
            'normalization_method': 'min_max',
            'formula': '(value - min) / (max - min)',
            'note': 'æ¯ä¸ªä»»åŠ¡æœ€é•¿3åˆ†é’Ÿ'
        }
        
        # ROIæ³¨è§†æ—¶é—´å½’ä¸€åŒ–
        roi_stats = self.stats.get('roi_fixation_time', {}).get('overall', {})
        config['features']['roi_fixation_time'] = {
            'name': 'ROIæ³¨è§†æ€»æ—¶é—´',
            'unit': 'ç§’',
            'min_value': 0.0,
            'max_value': roi_stats.get('q99', 25.0),  # ä½¿ç”¨99åˆ†ä½æ•°æˆ–é»˜è®¤25ç§’
            'normalization_method': 'min_max_clipped',
            'formula': 'clip((value - min) / (max - min), 0, 1)',
            'note': 'è¶…è¿‡æœ€å¤§å€¼çš„æˆªæ–­ä¸º1'
        }
        
        # ROIæ—¶é—´å æ¯”å½’ä¸€åŒ– (0-1ï¼Œå·²ç»æ˜¯æ¯”ä¾‹)
        config['features']['roi_time_percentage'] = {
            'name': 'ROIæ—¶é—´å æ¯”',
            'unit': 'æ¯”ä¾‹',
            'min_value': 0.0,
            'max_value': 1.0,
            'normalization_method': 'direct',
            'formula': 'value',
            'note': 'å·²ç»æ˜¯0-1çš„æ¯”ä¾‹ï¼Œæ— éœ€å½’ä¸€åŒ–'
        }
        
        # RQAæŒ‡æ ‡å½’ä¸€åŒ–
        rqa_stats = self.stats.get('rqa_metrics', {})
        rqa_configs = {
            'RR-2D-xy': {'min': 0.0, 'max': 0.15, 'typical_range': '0.01-0.05'},
            'RR-1D-x': {'min': 0.0, 'max': 0.20, 'typical_range': '0.03-0.10'},
            'DET-2D-xy': {'min': 0.0, 'max': 1.0, 'typical_range': '0.60-0.95'},
            'DET-1D-x': {'min': 0.0, 'max': 1.0, 'typical_range': '0.60-0.90'},
            'ENT-2D-xy': {'min': 0.0, 'max': 5.0, 'typical_range': '1.0-3.5'},
            'ENT-1D-x': {'min': 0.0, 'max': 5.0, 'typical_range': '1.0-3.0'}
        }
        
        for metric, ranges in rqa_configs.items():
            actual_stats = rqa_stats.get(metric, {}).get('overall', {})
            config['features'][metric] = {
                'name': f'RQAæŒ‡æ ‡-{metric}',
                'unit': 'æ— é‡çº²',
                'min_value': ranges['min'],
                'max_value': actual_stats.get('q99', ranges['max']),
                'normalization_method': 'min_max_clipped',
                'formula': 'clip((value - min) / (max - min), 0, 1)',
                'typical_range': ranges['typical_range'],
                'actual_range': f"{actual_stats.get('min', 'N/A'):.4f}-{actual_stats.get('max', 'N/A'):.4f}" if actual_stats else 'N/A'
            }
        
        return config
    
    def run_full_analysis(self) -> Dict:
        """è¿è¡Œå®Œæ•´åˆ†æ"""
        print("ğŸš€ å¼€å§‹å®Œæ•´æ•°æ®èŒƒå›´åˆ†æ...")
        
        # 1. åˆ†ææ¸¸æˆæ—¶é•¿
        duration_stats = self.analyze_game_duration()
        print(f"âœ… æ¸¸æˆæ—¶é•¿åˆ†æå®Œæˆ: {duration_stats.get('count', 0)} ä¸ªæ–‡ä»¶")
        
        # 2. åˆ†æROIæ³¨è§†æ—¶é—´
        roi_stats = self.analyze_roi_fixation_time()
        print(f"âœ… ROIæ—¶é—´åˆ†æå®Œæˆ")
        
        # 3. åˆ†æRQAæŒ‡æ ‡
        rqa_stats = self.analyze_rqa_metrics()
        print(f"âœ… RQAæŒ‡æ ‡åˆ†æå®Œæˆ")
        
        # 4. è®¡ç®—ROIæ—¶é—´å æ¯”
        percentage_stats = self.calculate_roi_time_percentage()
        print(f"âœ… ROIå æ¯”åˆ†æå®Œæˆ")
        
        # 5. ç”Ÿæˆå½’ä¸€åŒ–é…ç½®
        norm_config = self.generate_normalization_config()
        print(f"âœ… å½’ä¸€åŒ–é…ç½®ç”Ÿæˆå®Œæˆ")
        
        # ä¿å­˜ç»“æœ
        results = {
            'analysis_summary': {
                'game_duration': duration_stats,
                'roi_fixation_time': roi_stats,
                'rqa_metrics': rqa_stats,
                'roi_time_percentage': percentage_stats
            },
            'normalization_config': norm_config,
            'timestamp': pd.Timestamp.now().isoformat()
        }
        
        return results
    
    def save_results(self, results: Dict, output_path: str):
        """ä¿å­˜åˆ†æç»“æœ"""
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        print(f"ğŸ“ ç»“æœå·²ä¿å­˜åˆ°: {output_path}")

def main():
    """ä¸»å‡½æ•°"""
    analyzer = DataRangeAnalyzer()
    results = analyzer.run_full_analysis()
    
    # ä¿å­˜ç»“æœ
    os.makedirs('analysis_results', exist_ok=True)
    analyzer.save_results(results, 'analysis_results/data_range_analysis.json')
    
    # æ‰“å°æ‘˜è¦
    print("\nğŸ“Š æ•°æ®èŒƒå›´åˆ†ææ‘˜è¦:")
    print("=" * 50)
    
    if 'game_duration' in results['analysis_summary']:
        duration = results['analysis_summary']['game_duration']
        if 'min' in duration:
            print(f"ğŸ® æ¸¸æˆæ—¶é•¿: {duration['min']:.1f}s - {duration['max']:.1f}s (å¹³å‡: {duration['mean']:.1f}s)")
    
    if 'roi_fixation_time' in results['analysis_summary']:
        roi = results['analysis_summary']['roi_fixation_time'].get('overall', {})
        if 'min' in roi:
            print(f"ğŸ‘ï¸ ROIæ³¨è§†æ—¶é—´: {roi['min']:.3f}s - {roi['max']:.3f}s (å¹³å‡: {roi['mean']:.3f}s)")
    
    if 'rqa_metrics' in results['analysis_summary']:
        rqa = results['analysis_summary']['rqa_metrics']
        for metric, stats in rqa.items():
            if 'overall' in stats:
                overall = stats['overall']
                print(f"ğŸ”„ {metric}: {overall['min']:.4f} - {overall['max']:.4f}")
    
    print("\nâœ… åˆ†æå®Œæˆï¼è¯·æŸ¥çœ‹ analysis_results/data_range_analysis.json è·å–è¯¦ç»†ç»“æœ")

if __name__ == "__main__":
    main()