# -*- coding: utf-8 -*-
"""
æ§åˆ¶ç»„ç¬¬1ç»„æ•°æ®ä¸“ç”¨å¤„ç†å™¨
ä¸“é—¨å¤„ç†é¡¹ç›®å†…çš„ç¬¬1ç»„æ•°æ®ï¼ˆåŸç¬¬21ç»„æ•°æ®ï¼‰
"""
import os
import sys
import re
import math
import numpy as np
import pandas as pd
from tqdm import tqdm
from datetime import datetime
from typing import List, Tuple, Optional, Dict
from scipy import stats

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
from config.config import *

def parse_new_format(content: str) -> List[Dict]:
    """
    è§£ææ–°æ ¼å¼çš„çœ¼åŠ¨æ•°æ®
    
    Args:
        content: åŸå§‹æ–‡ä»¶å†…å®¹
        
    Returns:
        è§£æåçš„æ•°æ®è®°å½•åˆ—è¡¨
    """
    records = []
    lines = content.strip().split('\n')
    
    for line in lines:
        line = line.strip()
        if not line or line.startswith('#'):
            continue
            
        # åŒ¹é…æ•°æ®è¡Œæ ¼å¼: timestamp x y
        match = re.match(r'(\d+(?:\.\d+)?)\s+([0-9.]+)\s+([0-9.]+)', line)
        if match:
            timestamp_str, x_str, y_str = match.groups()
            
            try:
                timestamp = float(timestamp_str)
                x = float(x_str)
                y = float(y_str)
                
                # éªŒè¯åæ ‡èŒƒå›´
                if 0.0 <= x <= 1.0 and 0.0 <= y <= 1.0:
                    records.append({
                        'timestamp': timestamp,
                        'x': x,
                        'y': y
                    })
                    
            except ValueError:
                continue
                
    return records

def preprocess_vr_eyetracking(records: List[Dict], fov_deg: float = 110.0, 
                            velocity_threshold: float = 1000.0, 
                            z_score_threshold: float = 3.0) -> pd.DataFrame:
    """
    é¢„å¤„ç†VRçœ¼åŠ¨æ•°æ®
    
    Args:
        records: åŸå§‹æ•°æ®è®°å½•
        fov_deg: è§†åœºè§’åº¦æ•°
        velocity_threshold: é€Ÿåº¦è¿‡æ»¤é˜ˆå€¼ (deg/s)
        z_score_threshold: Z-scoreè¿‡æ»¤é˜ˆå€¼
        
    Returns:
        é¢„å¤„ç†åçš„DataFrame
    """
    if not records:
        return pd.DataFrame()
        
    # è½¬æ¢ä¸ºDataFrame
    df = pd.DataFrame(records)
    
    if len(df) < 2:
        print(f"  å¹³å‡é€Ÿåº¦: {0:.2f} deg/s")
        print(f"  æœ€å¤§é€Ÿåº¦: {0:.2f} deg/s")
        print(f"  æœ€å°é€Ÿåº¦: {0:.2f} deg/s")
        return df
        
    # æ’åºç¡®ä¿æ—¶é—´é¡ºåº
    df = df.sort_values('timestamp').reset_index(drop=True)
    
    print(f"  XèŒƒå›´: {df['x'].min():.3f} ~ {df['x'].max():.3f}, "
          f"YèŒƒå›´: {df['y'].min():.3f} ~ {df['y'].max():.3f}")
    
    # è®¡ç®—æ—¶é—´å·®
    df['time_diff'] = df['timestamp'].diff().fillna(0) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
    
    print(f"  time_diffèŒƒå›´: {df['time_diff'].min():.2f} ms ~ {df['time_diff'].max():.2f} ms")
    
    # åæ ‡è½¬æ¢ä¸ºè§†åœºè§’åº¦
    half_fov = fov_deg / 2.0
    df['x_deg'] = (df['x'] - 0.5) * fov_deg  # -55 to +55 åº¦
    df['y_deg'] = (df['y'] - 0.5) * fov_deg  # -55 to +55 åº¦
    
    print(f"\n[æ˜ å°„åˆ°è§†åœºè§’] Â±{half_fov}Â°:")
    print(f"  x_deg: {df['x_deg'].min():.3f} to {df['x_deg'].max():.3f}")
    print(f"  y_deg: {df['y_deg'].min():.3f} to {df['y_deg'].max():.3f}")
    
    # è®¡ç®—è§’é€Ÿåº¦
    df['velocity_deg_s'] = 0.0
    
    for i in range(1, len(df)):
        dt = df.iloc[i]['time_diff'] / 1000.0  # è½¬æ¢ä¸ºç§’
        
        if dt > 0:
            dx_deg = df.iloc[i]['x_deg'] - df.iloc[i-1]['x_deg']
            dy_deg = df.iloc[i]['y_deg'] - df.iloc[i-1]['y_deg']
            
            # è®¡ç®—æ¬§å‡ é‡Œå¾—è·ç¦»çš„è§’åº¦å˜åŒ–
            angular_distance = math.sqrt(dx_deg**2 + dy_deg**2)
            velocity = angular_distance / dt
            
            df.iloc[i, df.columns.get_loc('velocity_deg_s')] = velocity
    
    # æ˜¾ç¤ºé€Ÿåº¦ç»Ÿè®¡
    print(f"\n[é€Ÿåº¦ç»Ÿè®¡] velocity_deg_s:")
    print(f"  å¹³å‡é€Ÿåº¦: {df['velocity_deg_s'].mean():.2f} deg/s")
    print(f"  æœ€å¤§é€Ÿåº¦: {df['velocity_deg_s'].max():.2f} deg/s")
    print(f"  æœ€å°é€Ÿåº¦: {df['velocity_deg_s'].min():.2f} deg/s")
    
    # é€Ÿåº¦è¿‡æ»¤
    initial_count = len(df)
    df = df[df['velocity_deg_s'] <= velocity_threshold]
    after_velocity_filter = len(df)
    
    print(f"\né€Ÿåº¦è¿‡æ»¤: {initial_count} -> {after_velocity_filter} è¡Œ (é˜ˆå€¼: {velocity_threshold} deg/s)")
    
    if len(df) < 2:
        return df
        
    # Z-scoreè¿‡æ»¤å¼‚å¸¸å€¼
    velocity_z_scores = np.abs(stats.zscore(df['velocity_deg_s']))
    df = df[velocity_z_scores <= z_score_threshold]
    after_z_score_filter = len(df)
    
    print(f"Z-scoreè¿‡æ»¤: {after_velocity_filter} -> {after_z_score_filter} è¡Œ (é˜ˆå€¼: {z_score_threshold})")
    
    # è®¡ç®—æ‰«è§†é€Ÿåº¦ç»Ÿè®¡
    saccade_velocities = df[df['velocity_deg_s'] > 30]['velocity_deg_s']  # è®¤ä¸º>30 deg/sä¸ºæ‰«è§†
    if len(saccade_velocities) > 0:
        print(f"å¹³å‡æ‰«è§†é€Ÿåº¦: {saccade_velocities.mean():.2f} deg/s")
    
    # é‡æ–°ç´¢å¼•
    df = df.reset_index(drop=True)
    
    return df

def main():
    """å¤„ç†æ§åˆ¶ç»„ç¬¬1ç»„æ•°æ®"""
    if validate_config():
        print("âœ“ Configuration validation passed")
    else:
        print("âœ— Configuration validation failed")
        return
    
    print("ğŸ”„ å¤„ç†é¡¹ç›®å†…ç¬¬1ç»„æ•°æ® (åŸç¬¬21ç»„)")
    print("=" * 50)
    
    # å®šä¹‰è·¯å¾„
    raw_dir = "data/control_raw/control_group_1/rawdata"
    processed_dir = "data/control_processed"  # è¾“å‡ºç›´æ¥åˆ°processed
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(processed_dir, exist_ok=True)
    
    # æŸ¥æ‰¾TXTæ–‡ä»¶
    txt_files = []
    for file in os.listdir(raw_dir):
        if file.endswith('.txt'):
            txt_files.append(file)
    
    txt_files.sort()  # æŒ‰æ–‡ä»¶åæ’åº
    
    if not txt_files:
        print(f"âš ï¸  åœ¨ {raw_dir} ä¸­æœªæ‰¾åˆ°TXTæ–‡ä»¶")
        return
    
    success_count = 0
    failed_count = 0
    
    # å¤„ç†æ¯ä¸ªæ–‡ä»¶
    for txt_file in tqdm(txt_files, desc="å¤„ç†æ–‡ä»¶"):
        input_path = os.path.join(raw_dir, txt_file)
        
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å: n1q1_preprocessed.csv, n1q2_preprocessed.csv, ...
        base_name = os.path.splitext(txt_file)[0]
        output_filename = f"n1q{base_name}_preprocessed.csv"
        output_path = os.path.join(processed_dir, output_filename)
        
        print(f"\n=== å¤„ç†: {input_path} ===")
        
        try:
            # è¯»å–æ–‡ä»¶
            with open(input_path, 'r', encoding=INPUT_ENCODING) as f:
                content = f.read()
            
            # è§£ææ•°æ®
            records = parse_new_format(content)
            print(f"  è§£æåˆ° {len(records)} æ¡è®°å½•.")
            
            if not records:
                print("  âš ï¸  æœªæ‰¾åˆ°æœ‰æ•ˆæ•°æ®")
                failed_count += 1
                continue
                
            # é¢„å¤„ç†æ•°æ®
            df = preprocess_vr_eyetracking(
                records, 
                fov_deg=FOV_DEGREE,
                velocity_threshold=VELOCITY_THRESHOLD,
                z_score_threshold=STATISTICS_CONFIG['z_score_threshold']
            )
            
            if df.empty:
                print("  âš ï¸  é¢„å¤„ç†åæ•°æ®ä¸ºç©º")
                failed_count += 1
                continue
            
            # ä¿å­˜ç»“æœ
            df.to_csv(output_path, index=False, encoding=OUTPUT_ENCODING)
            print(f"\næœ€ç»ˆè®°å½•æ•°= {len(df)}")
            print(f"  => å·²ä¿å­˜: {output_path}")
            
            success_count += 1
            
        except Exception as e:
            print(f"  âŒ å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {e}")
            failed_count += 1
    
    print("\n" + "=" * 50)
    print(f"âœ… ç¬¬1ç»„æ•°æ®å¤„ç†å®Œæˆï¼")
    print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {processed_dir}")
    print(f"ğŸ“Š æˆåŠŸ: {success_count}, å¤±è´¥: {failed_count}, æ€»è®¡: {len(txt_files)}")

if __name__ == "__main__":
    main() 