# å¼€å‘æŒ‡å— (Development Guide)

## ğŸ“‹ ç›®å½•

1. [å¼€å‘ç¯å¢ƒé…ç½®](#-å¼€å‘ç¯å¢ƒé…ç½®)
2. [é¡¹ç›®ç»“æ„è¯´æ˜](#-é¡¹ç›®ç»“æ„è¯´æ˜)
3. [ä»£ç è§„èŒƒ](#-ä»£ç è§„èŒƒ)
4. [å¼€å‘æµç¨‹](#-å¼€å‘æµç¨‹)
5. [æµ‹è¯•æŒ‡å—](#-æµ‹è¯•æŒ‡å—)
6. [éƒ¨ç½²æŒ‡å—](#-éƒ¨ç½²æŒ‡å—)
7. [æ€§èƒ½ä¼˜åŒ–](#-æ€§èƒ½ä¼˜åŒ–)
8. [æ•…éšœæ’é™¤](#-æ•…éšœæ’é™¤)

---

## ğŸ› ï¸ å¼€å‘ç¯å¢ƒé…ç½®

### ç³»ç»Ÿè¦æ±‚

- **æ“ä½œç³»ç»Ÿ**: Windows 10+, macOS 10.15+, Ubuntu 18.04+
- **Python**: 3.8+ (æ¨è 3.9)
- **å†…å­˜**: æœ€å°‘4GBï¼Œæ¨è8GB+
- **å­˜å‚¨**: è‡³å°‘2GBå¯ç”¨ç©ºé—´
- **æµè§ˆå™¨**: Chrome 90+, Firefox 88+, Edge 90+

### ç¯å¢ƒå®‰è£…æ­¥éª¤

```bash
# 1. å…‹éš†é¡¹ç›®
git clone <repository-url>
cd az

# 2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv venv

# 3. æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
# Windows
venv\Scripts\activate
# macOS/Linux  
source venv/bin/activate

# 4. å®‰è£…ä¾èµ–
pip install -r requirements.txt

# 5. éªŒè¯å®‰è£…
python -c "import flask, numpy, pandas, matplotlib; print('âœ… ä¾èµ–å®‰è£…æˆåŠŸ')"

# 6. å¯åŠ¨å¼€å‘æœåŠ¡å™¨
python start_server.py
```

### å¼€å‘å·¥å…·æ¨è

- **IDE**: PyCharm Professional, VS Code
- **ä»£ç æ ¼å¼åŒ–**: Black, autopep8
- **ä»£ç æ£€æŸ¥**: pylint, flake8
- **APIæµ‹è¯•**: Postman, Insomnia
- **ç‰ˆæœ¬æ§åˆ¶**: Git + GitHub/GitLab
- **æ–‡æ¡£ç¼–å†™**: Markdownç¼–è¾‘å™¨

---

## ğŸ“ é¡¹ç›®ç»“æ„è¯´æ˜

### æ ¸å¿ƒç›®å½•ç»“æ„

```
az/
â”œâ”€â”€ ğŸ“‚ analysis/                    # ğŸ”¬ æ ¸å¿ƒåˆ†ææ¨¡å—
â”‚   â”œâ”€â”€ rqa_batch_renderer.py      # RQAæ‰¹é‡æ¸²æŸ“ (æ ¸å¿ƒç±»: 2000+ è¡Œ)
â”‚   â”œâ”€â”€ time_calibration.py        # æ—¶é—´æ ¡å‡†ç®—æ³•
â”‚   â”œâ”€â”€ data_processor.py          # æ•°æ®é¢„å¤„ç†é€»è¾‘
â”‚   â””â”€â”€ event_analyzer.py          # çœ¼åŠ¨äº‹ä»¶åˆ†æ
â”œâ”€â”€ ğŸ“‚ visualization/               # ğŸ¨ å¯è§†åŒ–å’ŒAPI
â”‚   â”œâ”€â”€ rqa_api_extension.py       # RQAç›¸å…³APIæ¥å£
â”‚   â”œâ”€â”€ rqa_pipeline_api.py        # ğŸ†• RQAåˆ†ææµç¨‹API (å®Œæ•´pipeline)
â”‚   â”œâ”€â”€ web_api.py                 # åŸºç¡€Web API
â”‚   â”œâ”€â”€ enhanced_web_visualizer.py # ä¸»WebæœåŠ¡å™¨
â”‚   â””â”€â”€ templates/
â”‚       â””â”€â”€ enhanced_index.html    # å‰ç«¯ç•Œé¢ (6000+ è¡Œï¼Œå«ç¬¬äº”æ¨¡å—)
â”œâ”€â”€ ğŸ“‚ data/                       # ğŸ’¾ æ•°æ®å­˜å‚¨
â”‚   â”œâ”€â”€ *_calibrated/              # æ ¡å‡†åæ•°æ®
â”‚   â”œâ”€â”€ event_analysis_results/    # äº‹ä»¶åˆ†æç»“æœ
â”‚   â”œâ”€â”€ rqa_results/               # RQAæ¸²æŸ“ç»“æœ
â”‚   â””â”€â”€ rqa_pipeline_results/      # ğŸ†• å‚æ•°åŒ–RQAåˆ†ææµç¨‹ç»“æœ
â”‚       â””â”€â”€ m{m}_tau{Ï„}_eps{Îµ}_lmin{l}/  # å‚æ•°ç­¾åç›®å½•
â”‚           â”œâ”€â”€ step1_rqa_calculation/   # æ­¥éª¤1ï¼šRQAè®¡ç®—
â”‚           â”œâ”€â”€ step2_data_merging/      # æ­¥éª¤2ï¼šæ•°æ®åˆå¹¶
â”‚           â”œâ”€â”€ step3_feature_enrichment/ # æ­¥éª¤3ï¼šç‰¹å¾è¡¥å……
â”‚           â”œâ”€â”€ step4_statistical_analysis/ # æ­¥éª¤4ï¼šç»Ÿè®¡åˆ†æ
â”‚           â”œâ”€â”€ step5_visualization/     # æ­¥éª¤5ï¼šå¯è§†åŒ–
â”‚           â””â”€â”€ metadata.json           # å‚æ•°å…ƒæ•°æ®
â”œâ”€â”€ ğŸ“‚ config/                     # âš™ï¸ é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ config.py                  # ä¸»é…ç½®
â”‚   â””â”€â”€ *.json                     # JSONé…ç½®æ–‡ä»¶
â””â”€â”€ ğŸ“‚ utils/                      # ğŸ› ï¸ å·¥å…·è„šæœ¬
    â””â”€â”€ *.py                       # å„ç§å·¥å…·å‡½æ•°
```

### å…³é”®æ–‡ä»¶è¯´æ˜

| æ–‡ä»¶ | è¡Œæ•° | åŠŸèƒ½ | ç»´æŠ¤éš¾åº¦ |
|------|------|------|----------|
| `rqa_batch_renderer.py` | 2000+ | RQAåˆ†ææ ¸å¿ƒé€»è¾‘ | â­â­â­â­â­ |
| `rqa_pipeline_api.py` | 1200+ | ğŸ†• RQAå®Œæ•´åˆ†ææµç¨‹ | â­â­â­â­â­ |
| `enhanced_index.html` | 6000+ | å‰ç«¯ä¸»ç•Œé¢(å«ç¬¬äº”æ¨¡å—) | â­â­â­â­ |
| `rqa_api_extension.py` | 500+ | RQA APIæ¥å£ | â­â­â­ |
| `web_api.py` | 800+ | åŸºç¡€APIæœåŠ¡ | â­â­â­ |
| `time_calibration.py` | 300+ | æ—¶é—´æ ¡å‡† | â­â­ |

---

## ğŸ”„ ç¬¬äº”æ¨¡å—ï¼šRQAå‚æ•°åŒ–åˆ†ææµç¨‹

### æ¨¡å—æ¦‚è¿°

ç¬¬äº”æ¨¡å—æ˜¯ä¸€ä¸ª**å®Œæ•´çš„çœ¼åŠ¨æ•°æ®RQAåˆ†ææµç¨‹**ï¼Œå®ç°äº†ä»åŸå§‹æ•°æ®å¤„ç†åˆ°ç»Ÿè®¡åˆ†æå†åˆ°å¯è§†åŒ–çš„å…¨è‡ªåŠ¨åŒ–pipelineã€‚è¯¥æ¨¡å—çš„æ ¸å¿ƒç‰¹ç‚¹æ˜¯**å‚æ•°åŒ–ç®¡ç†**ï¼Œæ”¯æŒä¸åŒRQAå‚æ•°ç»„åˆçš„å¹¶è¡Œåˆ†æå’Œç»“æœå¯¹æ¯”ã€‚

### æ ¸å¿ƒæ¶æ„

```mermaid
graph TD
    A[å‰ç«¯å‚æ•°é…ç½®] --> B[å‚æ•°ç­¾åç”Ÿæˆ]
    B --> C[ç›®å½•ç»“æ„åˆ›å»º]
    C --> D[æ­¥éª¤1: RQAè®¡ç®—]
    D --> E[æ­¥éª¤2: æ•°æ®åˆå¹¶]
    E --> F[æ­¥éª¤3: ç‰¹å¾è¡¥å……]
    F --> G[æ­¥éª¤4: ç»Ÿè®¡åˆ†æ]
    G --> H[æ­¥éª¤5: å¯è§†åŒ–]
    H --> I[ç»“æœå±•ç¤ºä¸ç®¡ç†]
    
    subgraph "å‚æ•°ç®¡ç†"
        J[å‚æ•°å†å²è®°å½•]
        K[ç»“æœå¯¹æ¯”åˆ†æ]
        L[æ‰¹é‡å¤„ç†ç®¡ç†]
    end
    
    I --> J
    I --> K
    I --> L
```

### å…³é”®æŠ€æœ¯ç‰¹æ€§

#### 1. å‚æ•°åŒ–ç®¡ç†ç³»ç»Ÿ
```python
def generate_param_signature(params):
    """ç”Ÿæˆå‚æ•°ç­¾åç”¨äºç›®å½•ç®¡ç†"""
    m = params.get('m', 2)
    tau = params.get('tau', 1)
    eps = params.get('eps', 0.05)
    lmin = params.get('lmin', 2)
    return f"m{m}_tau{tau}_eps{eps}_lmin{lmin}"

# ç›®å½•ç»“æ„ç¤ºä¾‹
# data/rqa_pipeline_results/
# â”œâ”€â”€ m2_tau1_eps0.05_lmin2/     # å‚æ•°ç»„åˆ1
# â”œâ”€â”€ m3_tau2_eps0.08_lmin3/     # å‚æ•°ç»„åˆ2
# â””â”€â”€ m2_tau1_eps0.03_lmin2/     # å‚æ•°ç»„åˆ3
```

#### 2. äº”æ­¥éª¤åˆ†ææµç¨‹

**æ­¥éª¤1: RQAè®¡ç®—**
- æ–‡ä»¶: `rqa_pipeline_api.py` - `rqa_calculate()`
- åŠŸèƒ½: å¯¹æ‰€æœ‰æ•°æ®æ–‡ä»¶æ‰§è¡ŒRQAåˆ†æ
- è¾“å‡º: `RQA_1D2D_summary_{group}.csv`

**æ­¥éª¤2: æ•°æ®åˆå¹¶**
- æ–‡ä»¶: `rqa_pipeline_api.py` - `data_merge()`
- åŠŸèƒ½: åˆå¹¶ä¸‰ç»„æ•°æ®(Control/MCI/AD)
- è¾“å‡º: `All_Subjects_RQA_EyeMetrics.csv`

**æ­¥éª¤3: ç‰¹å¾è¡¥å……**
- æ–‡ä»¶: `rqa_pipeline_api.py` - `feature_enrichment()`
- åŠŸèƒ½: è¡¥å……çœ¼åŠ¨äº‹ä»¶ç‰¹å¾å’ŒROIç»Ÿè®¡
- è¾“å‡º: `All_Subjects_RQA_EyeMetrics_Filled.csv`

**æ­¥éª¤4: ç»Ÿè®¡åˆ†æ**
- æ–‡ä»¶: `rqa_pipeline_api.py` - `statistical_analysis()`
- åŠŸèƒ½: å¤šå±‚æ¬¡ç»Ÿè®¡åˆ†æ
- è¾“å‡º: `group_stats_output.csv`, `multi_level_stats_output.csv`

**æ­¥éª¤5: å¯è§†åŒ–**
- æ–‡ä»¶: `rqa_pipeline_api.py` - `create_visualization()`
- åŠŸèƒ½: ç”Ÿæˆç»Ÿè®¡å›¾è¡¨å’Œè¶‹åŠ¿åˆ†æ
- è¾“å‡º: PNGå›¾è¡¨æ–‡ä»¶ + JSONæ•°æ®

#### 3. æ•°æ®å…¼å®¹æ€§å¤„ç†

```python
# çµæ´»çš„åˆ—åæ˜ å°„æœºåˆ¶
col_mapping = {
    'Duration_ms': ['Duration_ms', 'duration_ms', 'Duration'],
    'Amplitude': ['Amplitude_deg', 'SaccadeAmplitude', 'amplitude'],
    'FixationDuration': ['FixationDuration', 'FixTime', 'fixation_duration']
}

def build_event_aggregates(events_csv_path):
    """æ„é€ äº‹ä»¶çº§èšåˆï¼Œæ”¯æŒå¤šç§åˆ—åæ ¼å¼"""
    # è‡ªåŠ¨æ£€æµ‹å’Œæ˜ å°„åˆ—å
    actual_cols = {}
    for key, possible_names in col_mapping.items():
        for name in possible_names:
            if name in available_cols:
                actual_cols[key] = name
                break
```

#### 4. å¯è§†åŒ–å¢å¼º

**ç»„çº§æ¡å½¢å›¾**
- æ”¯æŒ RR-2D-xy, DET-2D-xy, ENT-2D-xy æŒ‡æ ‡
- è‡ªåŠ¨ç”Ÿæˆå‡å€¼Â±æ ‡å‡†å·®å›¾è¡¨
- ç»Ÿä¸€çš„é¢œè‰²ä¸»é¢˜

**ä»»åŠ¡é—´è¶‹åŠ¿å›¾**
- "Average RR (2D-xy) across tasks by Group"
- æ”¯æŒæ ‡å‡†å·®åŒºåŸŸæ˜¾ç¤º
- æ ·æœ¬æ•°é‡æ ‡æ³¨

```python
def create_task_trend_chart(df, metric="RR-2D-xy"):
    """åˆ›å»ºä»»åŠ¡é—´å˜åŒ–æŠ˜çº¿å›¾"""
    colors = {'Control': '#4472C4', 'MCI': '#E15759', 'AD': '#70AD47'}
    
    # è®¡ç®—ç»„çº§ç»Ÿè®¡
    avg_by_group = df_clean.groupby(['Group', 'q'])[metric].agg(['mean', 'std', 'count'])
    
    # ç»˜åˆ¶è¶‹åŠ¿çº¿å’Œæ ‡å‡†å·®åŒºåŸŸ
    for group in ['Control', 'MCI', 'AD']:
        group_data = avg_by_group[avg_by_group['Group'] == group]
        plt.plot(group_data['q'], group_data['mean'], 
                marker='o', label=f'{group} (nâ‰ˆ{total_count:.0f})', 
                color=colors[group])
        plt.fill_between(group_data['q'],
                        group_data['mean'] - group_data['std'],
                        group_data['mean'] + group_data['std'],
                        color=colors[group], alpha=0.2)
```

### å‰ç«¯ç•Œé¢è®¾è®¡

#### 1. å‚æ•°é…ç½®é¢æ¿
```html
<div class="rqa-parameter-config">
    <div class="param-row">
        <label>åµŒå…¥ç»´åº¦ (m):</label>
        <input type="number" id="rqa-m" value="2" min="1" max="10">
    </div>
    <div class="param-row">
        <label>æ—¶é—´å»¶è¿Ÿ (Ï„):</label>
        <input type="number" id="rqa-tau" value="1" min="1" max="10">
    </div>
    <!-- å‚æ•°ç­¾åæ˜¾ç¤º -->
    <div class="param-signature">
        å½“å‰å‚æ•°: <span id="param-display">m2_tau1_eps0.05_lmin2</span>
    </div>
</div>
```

#### 2. äº”æ­¥éª¤è¿›åº¦æŒ‡ç¤ºå™¨
```javascript
function updateStepStatus(stepNumber, status) {
    const stepElement = document.getElementById(`step${stepNumber}`);
    stepElement.className = `pipeline-step ${status}`;
    
    const statusText = {
        'pending': 'ç­‰å¾…ä¸­',
        'running': 'è¿è¡Œä¸­...',
        'completed': 'å·²å®Œæˆ',
        'error': 'å¤±è´¥'
    };
    
    stepElement.querySelector('.step-status').textContent = statusText[status];
}
```

#### 3. å†å²å‚æ•°ç®¡ç†
```javascript
async function loadParamHistory() {
    const response = await fetch('/api/rqa-pipeline/param-history');
    const data = await response.json();
    
    const historyList = document.getElementById('param-history-list');
    historyList.innerHTML = '';
    
    data.data.forEach(item => {
        const historyItem = document.createElement('div');
        historyItem.innerHTML = `
            <div class="history-item">
                <span class="signature">${item.signature}</span>
                <span class="progress">${item.progress.toFixed(1)}%</span>
                <button onclick="loadParams('${item.signature}')">åŠ è½½</button>
                <button onclick="viewResults('${item.signature}')">æŸ¥çœ‹</button>
                <button onclick="deleteResults('${item.signature}')">åˆ é™¤</button>
            </div>
        `;
        historyList.appendChild(historyItem);
    });
}
```

### APIæ¥å£è®¾è®¡

#### æ ¸å¿ƒAPIç«¯ç‚¹

| ç«¯ç‚¹ | æ–¹æ³• | åŠŸèƒ½ | å‚æ•° |
|------|------|------|------|
| `/api/rqa-pipeline/calculate` | POST | æ­¥éª¤1ï¼šRQAè®¡ç®— | `{parameters: {m, tau, eps, lmin}}` |
| `/api/rqa-pipeline/merge` | POST | æ­¥éª¤2ï¼šæ•°æ®åˆå¹¶ | `{parameters: {...}}` |
| `/api/rqa-pipeline/enrich` | POST | æ­¥éª¤3ï¼šç‰¹å¾è¡¥å…… | `{parameters: {...}}` |
| `/api/rqa-pipeline/analyze` | POST | æ­¥éª¤4ï¼šç»Ÿè®¡åˆ†æ | `{parameters: {...}}` |
| `/api/rqa-pipeline/visualize` | POST | æ­¥éª¤5ï¼šå¯è§†åŒ– | `{parameters: {...}}` |
| `/api/rqa-pipeline/status` | GET | è·å–æµç¨‹çŠ¶æ€ | `?m=2&tau=1&eps=0.05&lmin=2` |
| `/api/rqa-pipeline/param-history` | GET | å‚æ•°å†å²è®°å½• | æ—  |
| `/api/rqa-pipeline/results/<signature>` | GET | è·å–ç‰¹å®šç»“æœ | URLå‚æ•° |
| `/api/rqa-pipeline/delete/<signature>` | DELETE | åˆ é™¤ç»“æœ | URLå‚æ•° |

#### å“åº”æ ¼å¼æ ‡å‡†

```json
{
    "status": "success",
    "message": "RQAè®¡ç®—å®Œæˆ",
    "data": {
        "param_signature": "m2_tau1_eps0.05_lmin2",
        "total_files": 305,
        "control_files": 100,
        "mci_files": 105,
        "ad_files": 100,
        "output_directory": "data/rqa_pipeline_results/m2_tau1_eps0.05_lmin2/step1_rqa_calculation"
    }
}
```

### æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

#### 1. å†…å­˜ç®¡ç†
```python
def process_rqa_with_memory_management(file_paths, parameters):
    """å†…å­˜ä¼˜åŒ–çš„RQAå¤„ç†"""
    for file_path in file_paths:
        try:
            result = process_single_rqa_file(file_path, **parameters)
            yield result
        finally:
            # å¼ºåˆ¶åƒåœ¾å›æ”¶
            import gc
            gc.collect()
            # æ¸…ç†matplotlibå›¾å½¢
            plt.close('all')
```

#### 2. æ‰¹é‡å¤„ç†ä¼˜åŒ–
```python
# åˆ†æ‰¹å¤„ç†å¤§æ•°æ®é›†
BATCH_SIZE = 50
for i in range(0, len(files), BATCH_SIZE):
    batch_files = files[i:i+BATCH_SIZE]
    batch_results = process_batch(batch_files)
    save_batch_results(batch_results)
```

#### 3. å¼‚æ­¥å¤„ç†
```javascript
// å‰ç«¯å¼‚æ­¥çŠ¶æ€ç›‘æ§
async function monitorPipelineProgress() {
    const checkInterval = 2000; // 2ç§’æ£€æŸ¥ä¸€æ¬¡
    
    while (pipelineRunning) {
        try {
            const response = await fetch(`/api/rqa-pipeline/status?${currentParams}`);
            const status = await response.json();
            updateProgressUI(status);
            await sleep(checkInterval);
        } catch (error) {
            console.error('çŠ¶æ€æ£€æŸ¥å¤±è´¥:', error);
            break;
        }
    }
}
```

### æ•…éšœæ’é™¤

#### å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ

**é—®é¢˜1: å‚æ•°ç›®å½•åˆ›å»ºå¤±è´¥**
```python
# ç¡®ä¿ç›®å½•æƒé™æ­£ç¡®
import os
import stat

def ensure_directory_permissions(directory):
    if not os.path.exists(directory):
        os.makedirs(directory, mode=0o755)
    else:
        os.chmod(directory, stat.S_IRWXU | stat.S_IRGRP | stat.S_IXGRP)
```

**é—®é¢˜2: åˆ—åå…¼å®¹æ€§é—®é¢˜**
```python
# æ·»åŠ è°ƒè¯•ä¿¡æ¯
def debug_column_mapping(df_path):
    df = pd.read_csv(df_path)
    print(f"å¯ç”¨åˆ—: {df.columns.tolist()}")
    
    # æ£€æŸ¥æ¯ä¸ªæ˜ å°„
    for key, possible_names in col_mapping.items():
        found = [name for name in possible_names if name in df.columns]
        print(f"{key}: æ‰¾åˆ° {found}")
```

**é—®é¢˜3: å¯è§†åŒ–matplotlibé”™è¯¯**
```python
# å›¾ä¾‹å…¼å®¹æ€§ä¿®å¤
try:
    legend = plt.legend(title="Cognitive Groups", loc='best')
    legend.get_title().set_fontweight('bold')
except TypeError:
    # é™çº§å¤„ç†
    plt.legend(title="Cognitive Groups", loc='best')
```

---

## ğŸ“ ä»£ç è§„èŒƒ

### Pythonä»£ç è§„èŒƒ

#### 1. å‘½åè§„èŒƒ

```python
# âœ… å¥½çš„å‘½å
class RQABatchRenderer:
    def __init__(self):
        self.embedding_dimension = 2
        self.recurrence_threshold = 0.05
    
    def compute_recurrence_matrix(self, signal_data):
        distance_matrix = self._calculate_distances(signal_data)
        return distance_matrix < self.recurrence_threshold
    
    def _calculate_distances(self, data):
        """ç§æœ‰æ–¹æ³•ä½¿ç”¨ä¸‹åˆ’çº¿å‰ç¼€"""
        pass

# âŒ ä¸å¥½çš„å‘½å
class rqa_renderer:
    def __init__(self):
        self.m = 2
        self.eps = 0.05
    
    def compute_RM(self, data):
        dm = self.calc_dist(data)
        return dm < self.eps
```

#### 2. å‡½æ•°è®¾è®¡

```python
# âœ… å¥½çš„å‡½æ•°è®¾è®¡
def plot_amplitude_with_roi_enhanced(
    self, 
    data_id: str, 
    signal_data: np.ndarray, 
    t_: np.ndarray, 
    df: pd.DataFrame, 
    roi_color_dict: Dict[str, Tuple[float, float, float]], 
    params: Dict[str, Any], 
    save_path: str, 
    events_dict: Dict[str, List[Dict]]
) -> Optional[str]:
    """
    ç”Ÿæˆå¢å¼ºçš„amplitudeå›¾ï¼ŒåŒ…å«ROIç€è‰²å’Œæ ‡æ³¨
    
    Args:
        data_id: æ•°æ®æ ‡è¯†ç¬¦
        signal_data: ä¿¡å·æ•°æ®æ•°ç»„
        t_: æ—¶é—´æ•°ç»„
        df: åŸå§‹æ•°æ®DataFrame
        roi_color_dict: ROIé¢œè‰²æ˜ å°„å­—å…¸
        params: æ¸²æŸ“å‚æ•°
        save_path: ä¿å­˜è·¯å¾„
        events_dict: äº‹ä»¶æ•°æ®å­—å…¸
        
    Returns:
        base64ç¼–ç çš„å›¾ç‰‡å­—ç¬¦ä¸²ï¼Œå¤±è´¥æ—¶è¿”å›None
        
    Raises:
        ValueError: å½“ä¿¡å·æ•°æ®æ ¼å¼ä¸æ­£ç¡®æ—¶
        IOError: å½“æ— æ³•ä¿å­˜å›¾ç‰‡æ—¶
    """
    # å®ç°é€»è¾‘...
    pass

# âŒ ä¸å¥½çš„å‡½æ•°è®¾è®¡
def plot_amp(self, did, data, t, df, colors, p, path, events):
    # æ²¡æœ‰ç±»å‹æ³¨è§£ï¼Œæ²¡æœ‰æ–‡æ¡£è¯´æ˜
    pass
```

#### 3. é”™è¯¯å¤„ç†

```python
# âœ… å¥½çš„é”™è¯¯å¤„ç†
def load_and_validate_data(self, file_path: str) -> pd.DataFrame:
    """åŠ è½½å¹¶éªŒè¯CSVæ•°æ®æ–‡ä»¶"""
    try:
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            
        df = pd.read_csv(file_path)
        
        # éªŒè¯å¿…éœ€åˆ—
        required_columns = ['timestamp', 'x', 'y']
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            raise ValueError(f"ç¼ºå°‘å¿…éœ€åˆ—: {missing_columns}")
            
        # æ•°æ®ç±»å‹éªŒè¯
        df['x'] = pd.to_numeric(df['x'], errors='coerce')
        df['y'] = pd.to_numeric(df['y'], errors='coerce')
        
        return df
        
    except pd.errors.EmptyDataError:
        print(f"âŒ æ•°æ®æ–‡ä»¶ä¸ºç©º: {file_path}")
        return pd.DataFrame()
    except Exception as e:
        print(f"âŒ åŠ è½½æ•°æ®å¤±è´¥ {file_path}: {e}")
        return pd.DataFrame()

# âŒ ä¸å¥½çš„é”™è¯¯å¤„ç†
def load_data(self, path):
    df = pd.read_csv(path)  # å¯èƒ½æŠ›å‡ºå¼‚å¸¸ä½†æ²¡æœ‰å¤„ç†
    return df
```

### JavaScriptä»£ç è§„èŒƒ

#### 1. å˜é‡å£°æ˜å’Œå‘½å

```javascript
// âœ… å¥½çš„JavaScriptä»£ç 
const RQA_CONFIG = {
    DEFAULT_EMBEDDING_DIMENSION: 2,
    DEFAULT_TIME_DELAY: 1,
    DEFAULT_THRESHOLD: 0.05
};

class RQAInterface {
    constructor() {
        this.currentParamSignature = '';
        this.renderingInProgress = false;
        this.resultsCache = new Map();
    }
    
    async startRQARendering(parameters) {
        try {
            this.renderingInProgress = true;
            this.updateUI('rendering');
            
            const response = await fetch('/api/rqa-batch-render', {
                method: 'POST',
                headers: {'Content-Type': 'application/json'},
                body: JSON.stringify(parameters)
            });
            
            if (!response.ok) {
                throw new Error(`HTTP ${response.status}: ${response.statusText}`);
            }
            
            const result = await response.json();
            this.currentParamSignature = result.param_signature;
            this.monitorProgress();
            
        } catch (error) {
            console.error('RQAæ¸²æŸ“å¯åŠ¨å¤±è´¥:', error);
            this.showError('å¯åŠ¨æ¸²æŸ“å¤±è´¥: ' + error.message);
        } finally {
            this.renderingInProgress = false;
        }
    }
}

// âŒ ä¸å¥½çš„JavaScriptä»£ç 
var config = {
    m: 2,
    tau: 1,
    eps: 0.05
};

function startRender(params) {
    // æ²¡æœ‰é”™è¯¯å¤„ç†
    fetch('/api/rqa-batch-render', {
        method: 'POST',
        body: JSON.stringify(params)
    }).then(response => response.json())
    .then(data => {
        // å¤„ç†å“åº”
    });
}
```

### HTML/CSSè§„èŒƒ

```html
<!-- âœ… å¥½çš„HTMLç»“æ„ -->
<div class="rqa-analysis-panel" id="rqa-analysis-panel">
    <div class="rqa-compact-filters">
        <div class="filters-grid">
            <div class="filter-item">
                <label for="rqa-analysis-mode" class="form-label">åˆ†ææ¨¡å¼:</label>
                <select id="rqa-analysis-mode" class="form-select">
                    <option value="1d_x">1Dä¿¡å· (Xåæ ‡)</option>
                    <option value="1d_amplitude">1Dä¿¡å· (å¹…åº¦)</option>
                    <option value="2d_xy" selected>2Dä¿¡å· (X,Yåæ ‡)</option>
                </select>
            </div>
        </div>
    </div>
</div>

<!-- CSSæ ·å¼ -->
<style>
.rqa-compact-filters {
    background-color: #f8f9fa;
    border: 1px solid #dee2e6;
    border-radius: 8px;
    padding: 1rem;
    margin-bottom: 1rem;
}

.filters-grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
    gap: 1rem;
    align-items: end;
}
</style>
```

---

## ğŸ”„ å¼€å‘æµç¨‹

### 1. åŠŸèƒ½å¼€å‘æµç¨‹

```mermaid
graph LR
    A[éœ€æ±‚åˆ†æ] --> B[è®¾è®¡æ–¹æ¡ˆ]
    B --> C[åˆ›å»ºåˆ†æ”¯]
    C --> D[ç¼–å†™ä»£ç ]
    D --> E[å•å…ƒæµ‹è¯•]
    E --> F[é›†æˆæµ‹è¯•]
    F --> G[ä»£ç å®¡æŸ¥]
    G --> H[åˆå¹¶ä¸»åˆ†æ”¯]
    H --> I[éƒ¨ç½²éªŒè¯]
```

### 2. Gitå·¥ä½œæµ

```bash
# 1. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯
git checkout -b feature/new-rqa-metric
git push -u origin feature/new-rqa-metric

# 2. å¼€å‘è¿‡ç¨‹ä¸­çš„æäº¤
git add .
git commit -m "feat: æ·»åŠ æ–°çš„RQAæŒ‡æ ‡LAMè®¡ç®—"
git push origin feature/new-rqa-metric

# 3. åŠŸèƒ½å®Œæˆå
git checkout main
git pull origin main
git checkout feature/new-rqa-metric
git rebase main
git push origin feature/new-rqa-metric

# 4. åˆ›å»ºPull Request
# é€šè¿‡Webç•Œé¢åˆ›å»ºPRï¼Œè¿›è¡Œä»£ç å®¡æŸ¥

# 5. åˆå¹¶åæ¸…ç†
git checkout main
git pull origin main
git branch -d feature/new-rqa-metric
git push origin --delete feature/new-rqa-metric
```

### 3. æäº¤ä¿¡æ¯è§„èŒƒ

```bash
# æ ¼å¼: <type>(<scope>): <subject>

# ç±»å‹ (type)
feat:     æ–°åŠŸèƒ½
fix:      ä¿®å¤bug
docs:     æ–‡æ¡£æ›´æ–°
style:    ä»£ç æ ¼å¼è°ƒæ•´
refactor: é‡æ„ä»£ç 
test:     æµ‹è¯•ç›¸å…³
chore:    æ„å»º/å·¥å…·ç›¸å…³

# ç¤ºä¾‹
feat(rqa): æ·»åŠ LAMé€’å½’é‡åŒ–æŒ‡æ ‡
fix(visualization): ä¿®å¤amplitudeå›¾ROIç€è‰²é—®é¢˜
docs(api): æ›´æ–°RQA APIæ–‡æ¡£
style(frontend): ç»Ÿä¸€JavaScriptä»£ç æ ¼å¼
refactor(analysis): é‡æ„ä¿¡å·åµŒå…¥ç®—æ³•
test(rqa): æ·»åŠ é€’å½’çŸ©é˜µè®¡ç®—å•å…ƒæµ‹è¯•
chore(deps): æ›´æ–°ä¾èµ–åŒ…ç‰ˆæœ¬
```

---

## ğŸ§ª æµ‹è¯•æŒ‡å—

### 1. å•å…ƒæµ‹è¯•

```python
# tests/test_rqa_renderer.py
import unittest
import numpy as np
import pandas as pd
from analysis.rqa_batch_renderer import RQABatchRenderer

class TestRQABatchRenderer(unittest.TestCase):
    
    def setUp(self):
        """æµ‹è¯•å‰çš„å‡†å¤‡å·¥ä½œ"""
        self.renderer = RQABatchRenderer()
        self.sample_data = pd.DataFrame({
            'timestamp': [0, 16, 32, 48, 64],
            'x': [100, 105, 110, 108, 103],
            'y': [200, 205, 210, 208, 203],
            'milliseconds': [0, 16, 32, 48, 64],
            'ROI': ['BG', 'INST', 'INST', 'KW', 'BG'],
            'SequenceID': [0, 1, 1, 2, 0]
        })
    
    def test_prepare_signal_data_1d_x(self):
        """æµ‹è¯•1D Xåæ ‡ä¿¡å·å‡†å¤‡"""
        signal = self.renderer.prepare_signal_data(self.sample_data, '1d_x')
        expected = np.array([100, 105, 110, 108, 103])
        np.testing.assert_array_equal(signal, expected)
    
    def test_prepare_signal_data_2d_xy(self):
        """æµ‹è¯•2D XYåæ ‡ä¿¡å·å‡†å¤‡"""
        signal = self.renderer.prepare_signal_data(self.sample_data, '2d_xy')
        expected = np.array([[100, 200], [105, 205], [110, 210], [108, 208], [103, 203]])
        np.testing.assert_array_equal(signal, expected)
    
    def test_embed_signal_1d(self):
        """æµ‹è¯•1Dä¿¡å·åµŒå…¥"""
        signal = np.array([1, 2, 3, 4, 5])
        embedded = self.renderer.embed_signal(signal, m=2, tau=1, mode='1d')
        expected = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])
        np.testing.assert_array_equal(embedded, expected)
    
    def test_compute_recurrence_matrix(self):
        """æµ‹è¯•é€’å½’çŸ©é˜µè®¡ç®—"""
        embedded = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])
        rm = self.renderer.compute_recurrence_matrix(embedded, epsilon=2.0, metric='euclidean')
        self.assertEqual(rm.shape, (4, 4))
        self.assertTrue(np.all(rm.diagonal()))  # å¯¹è§’çº¿åº”è¯¥å…¨ä¸ºTrue

if __name__ == '__main__':
    unittest.main()
```

### 2. APIæµ‹è¯•

```python
# tests/test_api.py
import unittest
import requests
import json
from time import sleep

class TestRQAAPI(unittest.TestCase):
    
    BASE_URL = "http://localhost:8080"
    
    def setUp(self):
        """ç¡®ä¿æœåŠ¡å™¨è¿è¡Œ"""
        try:
            response = requests.get(f"{self.BASE_URL}/api/system/status", timeout=5)
            self.assertTrue(response.status_code == 200)
        except requests.ConnectionError:
            self.skipTest("æœåŠ¡å™¨æœªè¿è¡Œ")
    
    def test_start_rqa_rendering(self):
        """æµ‹è¯•RQAæ¸²æŸ“å¯åŠ¨"""
        params = {
            "analysis_mode": "2d_xy",
            "distance_metric": "euclidean",
            "embedding_dimension": 2,
            "time_delay": 1,
            "recurrence_threshold": 0.05,
            "min_line_length": 2,
            "color_theme": "green_gradient"
        }
        
        response = requests.post(
            f"{self.BASE_URL}/api/rqa-batch-render",
            json=params,
            timeout=30
        )
        
        self.assertEqual(response.status_code, 200)
        data = response.json()
        self.assertEqual(data['status'], 'success')
        self.assertIn('param_signature', data)
    
    def test_get_render_status(self):
        """æµ‹è¯•æ¸²æŸ“çŠ¶æ€è·å–"""
        response = requests.get(f"{self.BASE_URL}/api/rqa-render-status", timeout=10)
        self.assertEqual(response.status_code, 200)
        
        data = response.json()
        self.assertIn('status', data)
        self.assertIn('total_files', data)
        self.assertIn('processed_files', data)

class TestRQAPipelineAPI(unittest.TestCase):
    """ç¬¬äº”æ¨¡å—ï¼šRQAåˆ†ææµç¨‹APIæµ‹è¯•"""
    
    BASE_URL = "http://localhost:8080"
    TEST_PARAMS = {
        "m": 2,
        "tau": 1, 
        "eps": 0.05,
        "lmin": 2
    }
    
    def setUp(self):
        """æµ‹è¯•å‰å‡†å¤‡"""
        self.param_signature = "m2_tau1_eps0.05_lmin2"
    
    def test_rqa_pipeline_calculate(self):
        """æµ‹è¯•æ­¥éª¤1ï¼šRQAè®¡ç®—"""
        response = requests.post(
            f"{self.BASE_URL}/api/rqa-pipeline/calculate",
            json={"parameters": self.TEST_PARAMS},
            timeout=60
        )
        
        self.assertEqual(response.status_code, 200)
        data = response.json()
        self.assertEqual(data['status'], 'success')
        self.assertIn('param_signature', data['data'])
        self.assertIn('total_files', data['data'])
    
    def test_rqa_pipeline_status(self):
        """æµ‹è¯•æµç¨‹çŠ¶æ€æŸ¥è¯¢"""
        response = requests.get(
            f"{self.BASE_URL}/api/rqa-pipeline/status",
            params=self.TEST_PARAMS,
            timeout=10
        )
        
        self.assertEqual(response.status_code, 200)
        data = response.json()
        self.assertIn('step_status', data['data'])
        self.assertIn('progress_percentage', data['data'])
    
    def test_param_history(self):
        """æµ‹è¯•å‚æ•°å†å²è®°å½•"""
        response = requests.get(
            f"{self.BASE_URL}/api/rqa-pipeline/param-history",
            timeout=10
        )
        
        self.assertEqual(response.status_code, 200)
        data = response.json()
        self.assertIn('data', data)
        self.assertIsInstance(data['data'], list)
    
    def test_visualization_results(self):
        """æµ‹è¯•å¯è§†åŒ–ç»“æœè·å–"""
        response = requests.get(
            f"{self.BASE_URL}/api/rqa-pipeline/results/{self.param_signature}",
            timeout=10
        )
        
        if response.status_code == 200:
            data = response.json()
            self.assertIn('data', data)
            if 'results' in data['data'] and 'charts' in data['data']['results']:
                charts = data['data']['results']['charts']
                self.assertIsInstance(charts, list)
                # éªŒè¯å›¾è¡¨æ•°æ®ç»“æ„
                if charts:
                    chart = charts[0]
                    self.assertIn('title', chart)
                    self.assertIn('metric', chart)
                    self.assertIn('image', chart)  # base64å›¾ç‰‡æ•°æ®
        elif response.status_code == 404:
            self.skipTest(f"å‚æ•°ç»„åˆ {self.param_signature} çš„ç»“æœä¸å­˜åœ¨")
    
    def test_full_pipeline_integration(self):
        """é›†æˆæµ‹è¯•ï¼šå®Œæ•´æµç¨‹"""
        steps = [
            ('calculate', 'æ­¥éª¤1ï¼šRQAè®¡ç®—'),
            ('merge', 'æ­¥éª¤2ï¼šæ•°æ®åˆå¹¶'), 
            ('enrich', 'æ­¥éª¤3ï¼šç‰¹å¾è¡¥å……'),
            ('analyze', 'æ­¥éª¤4ï¼šç»Ÿè®¡åˆ†æ'),
            ('visualize', 'æ­¥éª¤5ï¼šå¯è§†åŒ–')
        ]
        
        for step_name, step_desc in steps:
            with self.subTest(step=step_name):
                response = requests.post(
                    f"{self.BASE_URL}/api/rqa-pipeline/{step_name}",
                    json={"parameters": self.TEST_PARAMS},
                    timeout=120  # å¢åŠ è¶…æ—¶æ—¶é—´
                )
                
                # æ£€æŸ¥å“åº”
                if response.status_code == 200:
                    data = response.json()
                    self.assertEqual(data['status'], 'success')
                    print(f"âœ… {step_desc} æµ‹è¯•é€šè¿‡")
                elif response.status_code == 500:
                    # æ‰“å°é”™è¯¯ä¿¡æ¯ç”¨äºè°ƒè¯•
                    try:
                        error_data = response.json()
                        print(f"âŒ {step_desc} å¤±è´¥: {error_data.get('message', 'æœªçŸ¥é”™è¯¯')}")
                    except:
                        print(f"âŒ {step_desc} å¤±è´¥: HTTP 500")
                    self.fail(f"{step_desc} è¿”å›500é”™è¯¯")
                else:
                    self.fail(f"{step_desc} è¿”å›çŠ¶æ€ç : {response.status_code}")

if __name__ == '__main__':
    unittest.main()
```

### 3. è¿è¡Œæµ‹è¯•

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
python -m pytest tests/ -v

# è¿è¡Œç‰¹å®šæµ‹è¯•æ–‡ä»¶
python -m pytest tests/test_rqa_renderer.py -v

# è¿è¡Œæµ‹è¯•å¹¶ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
python -m pytest tests/ --cov=analysis --cov-report=html

# è¿è¡Œæ€§èƒ½æµ‹è¯•
python -m pytest tests/test_performance.py -v --benchmark-only
```

---

## ğŸš€ éƒ¨ç½²æŒ‡å—

### 1. æœ¬åœ°éƒ¨ç½²

```bash
# 1. ç¯å¢ƒå‡†å¤‡
python -m venv production_env
source production_env/bin/activate  # Linux/Mac
# æˆ– production_env\Scripts\activate  # Windows

# 2. å®‰è£…ä¾èµ–
pip install -r requirements.txt

# 3. ç¯å¢ƒå˜é‡é…ç½®
export FLASK_ENV=production
export FLASK_APP=start_server.py

# 4. å¯åŠ¨æœåŠ¡
python start_server.py
```

### 2. Dockeréƒ¨ç½²

```dockerfile
# Dockerfile
FROM python:3.9-slim

WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    && rm -rf /var/lib/apt/lists/*

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶é¡¹ç›®æ–‡ä»¶
COPY . .

# åˆ›å»ºæ•°æ®ç›®å½•
RUN mkdir -p data/rqa_results

# æš´éœ²ç«¯å£
EXPOSE 8080

# å¯åŠ¨å‘½ä»¤
CMD ["python", "start_server.py"]
```

```yaml
# docker-compose.yml
version: '3.8'

services:
  eyetracking-analysis:
    build: .
    ports:
      - "8080:8080"
    volumes:
      - ./data:/app/data
      - ./config:/app/config
    environment:
      - FLASK_ENV=production
    restart: unless-stopped
    
  # å¯é€‰ï¼šæ·»åŠ æ•°æ®åº“
  postgres:
    image: postgres:13
    environment:
      POSTGRES_DB: eyetracking
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"

volumes:
  postgres_data:
```

### 3. äº‘æœåŠ¡å™¨éƒ¨ç½²

```bash
# 1. æœåŠ¡å™¨å‡†å¤‡ (Ubuntu)
sudo apt update
sudo apt install python3 python3-pip python3-venv nginx

# 2. é¡¹ç›®éƒ¨ç½²
git clone <repository-url>
cd az
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# 3. SystemdæœåŠ¡é…ç½®
sudo vim /etc/systemd/system/eyetracking-analysis.service
```

```ini
[Unit]
Description=Eye-tracking Data Analysis System
After=network.target

[Service]
User=ubuntu
Group=ubuntu
WorkingDirectory=/home/ubuntu/az
Environment=PATH=/home/ubuntu/az/venv/bin
ExecStart=/home/ubuntu/az/venv/bin/python start_server.py
Restart=always

[Install]
WantedBy=multi-user.target
```

```bash
# 4. å¯åŠ¨æœåŠ¡
sudo systemctl daemon-reload
sudo systemctl enable eyetracking-analysis
sudo systemctl start eyetracking-analysis

# 5. Nginxåå‘ä»£ç†é…ç½®
sudo vim /etc/nginx/sites-available/eyetracking-analysis
```

```nginx
server {
    listen 80;
    server_name your_domain.com;
    
    location / {
        proxy_pass http://127.0.0.1:8080;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
    
    location /ws {
        proxy_pass http://127.0.0.1:8080;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
    }
}
```

---

## âš¡ æ€§èƒ½ä¼˜åŒ–

### 1. Pythonæ€§èƒ½ä¼˜åŒ–

```python
# âœ… ä½¿ç”¨NumPyå‘é‡åŒ–æ“ä½œ
def compute_distances_vectorized(embedded_data):
    """å‘é‡åŒ–çš„è·ç¦»è®¡ç®—"""
    n = len(embedded_data)
    distances = np.zeros((n, n))
    
    for i in range(n):
        # å‘é‡åŒ–è®¡ç®—æ‰€æœ‰è·ç¦»
        distances[i, :] = np.linalg.norm(embedded_data - embedded_data[i], axis=1)
    
    return distances

# âŒ é¿å…åµŒå¥—å¾ªç¯
def compute_distances_slow(embedded_data):
    """æ…¢çš„è·ç¦»è®¡ç®—æ–¹å¼"""
    n = len(embedded_data)
    distances = np.zeros((n, n))
    
    for i in range(n):
        for j in range(n):
            distances[i, j] = np.linalg.norm(embedded_data[i] - embedded_data[j])
    
    return distances
```

### 2. å†…å­˜ç®¡ç†

```python
def process_large_dataset(file_paths):
    """å¤„ç†å¤§æ•°æ®é›†çš„å†…å­˜ä¼˜åŒ–æ–¹æ³•"""
    for file_path in file_paths:
        try:
            # åˆ†å—è¯»å–å¤§æ–‡ä»¶
            chunk_size = 10000
            for chunk in pd.read_csv(file_path, chunksize=chunk_size):
                result = process_chunk(chunk)
                save_result(result)
                
        finally:
            # å¼ºåˆ¶åƒåœ¾å›æ”¶
            gc.collect()
            
            # æ¸…ç†matplotlibå›¾å½¢
            plt.close('all')
```

### 3. å¹¶å‘å¤„ç†

```python
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
import multiprocessing

def parallel_rqa_processing(file_list, max_workers=None):
    """å¹¶è¡Œå¤„ç†RQAåˆ†æ"""
    if max_workers is None:
        max_workers = min(multiprocessing.cpu_count(), 4)
    
    with ProcessPoolExecutor(max_workers=max_workers) as executor:
        futures = []
        for file_path in file_list:
            future = executor.submit(process_single_file, file_path)
            futures.append(future)
        
        # è·å–ç»“æœ
        results = []
        for future in futures:
            try:
                result = future.result(timeout=300)  # 5åˆ†é’Ÿè¶…æ—¶
                results.append(result)
            except Exception as e:
                print(f"å¤„ç†å¤±è´¥: {e}")
                
    return results
```

### 4. å‰ç«¯æ€§èƒ½ä¼˜åŒ–

```javascript
// âœ… é˜²æŠ–åŠ¨å‡½æ•°
function debounce(func, wait) {
    let timeout;
    return function executedFunction(...args) {
        const later = () => {
            clearTimeout(timeout);
            func(...args);
        };
        clearTimeout(timeout);
        timeout = setTimeout(later, wait);
    };
}

// ä½¿ç”¨é˜²æŠ–åŠ¨ä¼˜åŒ–æœç´¢
const debouncedSearch = debounce((query) => {
    searchResults(query);
}, 300);

// âœ… å›¾ç‰‡æ‡’åŠ è½½
function lazyLoadImages() {
    const images = document.querySelectorAll('img[data-src]');
    const imageObserver = new IntersectionObserver((entries, observer) => {
        entries.forEach(entry => {
            if (entry.isIntersecting) {
                const img = entry.target;
                img.src = img.dataset.src;
                img.removeAttribute('data-src');
                observer.unobserve(img);
            }
        });
    });
    
    images.forEach(img => imageObserver.observe(img));
}

// âœ… è™šæ‹Ÿæ»šåŠ¨
class VirtualScrollList {
    constructor(container, itemHeight, renderItem) {
        this.container = container;
        this.itemHeight = itemHeight;
        this.renderItem = renderItem;
        this.visibleItems = Math.ceil(container.clientHeight / itemHeight) + 2;
    }
    
    update(data) {
        const startIndex = Math.floor(this.container.scrollTop / this.itemHeight);
        const endIndex = Math.min(startIndex + this.visibleItems, data.length);
        
        this.container.innerHTML = '';
        for (let i = startIndex; i < endIndex; i++) {
            const item = this.renderItem(data[i], i);
            this.container.appendChild(item);
        }
    }
}
```

---

## ğŸ”§ æ•…éšœæ’é™¤

### 1. å¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ

#### é—®é¢˜1: RQAæ¸²æŸ“å¤±è´¥

**ç°è±¡**: 
```
âŒ Recurrence plot rendering failed c1q1: 'ENT'
```

**åŸå› **: RQAæŒ‡æ ‡è®¡ç®—é”™è¯¯

**è§£å†³æ–¹æ¡ˆ**:
```python
# æ£€æŸ¥compute_rqa_measureså‡½æ•°
def compute_rqa_measures(self, recurrence_matrix, min_line_length=2):
    try:
        # ç¡®ä¿æ­£ç¡®è¿”å›å­—å…¸æ ¼å¼
        rr = np.sum(recurrence_matrix) / (recurrence_matrix.size)
        det, ent = self.extract_diag_lengths(recurrence_matrix, min_line_length)
        
        return {
            'RR': float(rr),
            'DET': float(det),
            'ENT': float(ent)
        }
    except Exception as e:
        print(f"RQAæŒ‡æ ‡è®¡ç®—å¤±è´¥: {e}")
        return {'RR': 0.0, 'DET': 0.0, 'ENT': 0.0}
```

#### é—®é¢˜2: å†…å­˜ä¸è¶³

**ç°è±¡**: 
```
MemoryError: Unable to allocate array
```

**è§£å†³æ–¹æ¡ˆ**:
```python
# å‡å°‘æ‰¹é‡å¤„ç†å¤§å°
BATCH_SIZE = 50  # ä»100å‡å°‘åˆ°50

# å¢åŠ åƒåœ¾å›æ”¶
import gc
def process_with_memory_management():
    for i in range(0, len(files), BATCH_SIZE):
        batch = files[i:i+BATCH_SIZE]
        process_batch(batch)
        gc.collect()  # å¼ºåˆ¶åƒåœ¾å›æ”¶
```

#### é—®é¢˜3: æœåŠ¡å™¨æ— æ³•å¯åŠ¨

**ç°è±¡**: 
```
Address already in use: Port 8080
```

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æŸ¥æ‰¾å ç”¨ç«¯å£çš„è¿›ç¨‹
netstat -tulpn | grep 8080
# æˆ–
lsof -i :8080

# ç»ˆæ­¢è¿›ç¨‹
kill -9 <PID>

# æˆ–ä½¿ç”¨ä¸åŒç«¯å£
python start_server.py --port 8081
```

### 2. æ—¥å¿—åˆ†æ

```python
# é…ç½®è¯¦ç»†æ—¥å¿—
import logging

logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('eyetracking_analysis.log'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

# åœ¨å…³é”®ä½ç½®æ·»åŠ æ—¥å¿—
def critical_function():
    logger.info("å¼€å§‹æ‰§è¡Œå…³é”®å‡½æ•°")
    try:
        # ä¸šåŠ¡é€»è¾‘
        result = process_data()
        logger.info(f"å¤„ç†å®Œæˆï¼Œç»“æœ: {result}")
        return result
    except Exception as e:
        logger.error(f"æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
        raise
```

### 3. æ€§èƒ½ç›‘æ§

```python
import time
import psutil
from functools import wraps

def monitor_performance(func):
    """æ€§èƒ½ç›‘æ§è£…é¥°å™¨"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        start_time = time.time()
        start_memory = psutil.Process().memory_info().rss / 1024 / 1024
        
        try:
            result = func(*args, **kwargs)
            return result
        finally:
            end_time = time.time()
            end_memory = psutil.Process().memory_info().rss / 1024 / 1024
            
            duration = end_time - start_time
            memory_delta = end_memory - start_memory
            
            print(f"ğŸ” {func.__name__} æ€§èƒ½ç›‘æ§:")
            print(f"   æ‰§è¡Œæ—¶é—´: {duration:.2f}ç§’")
            print(f"   å†…å­˜å˜åŒ–: {memory_delta:+.2f}MB")
            
    return wrapper

# ä½¿ç”¨ç›‘æ§è£…é¥°å™¨
@monitor_performance
def expensive_function():
    # è€—æ—¶æ“ä½œ
    pass
```

---

## ğŸ“š å‚è€ƒèµ„æº

### å®˜æ–¹æ–‡æ¡£
- [Flaskæ–‡æ¡£](https://flask.palletsprojects.com/)
- [NumPyæ–‡æ¡£](https://numpy.org/doc/)
- [Pandasæ–‡æ¡£](https://pandas.pydata.org/docs/)
- [Matplotlibæ–‡æ¡£](https://matplotlib.org/stable/)

### å¼€å‘å·¥å…·
- [Pythonä»£ç é£æ ¼æŒ‡å— (PEP 8)](https://www.python.org/dev/peps/pep-0008/)
- [Gitæœ€ä½³å®è·µ](https://git-scm.com/book)
- [Markdownè¯­æ³•](https://www.markdownguide.org/)

### é¡¹ç›®ç›¸å…³
- [é¡¹ç›®README](README.md)
- [APIæ–‡æ¡£](API_DOCUMENTATION.md)
- [RQAç®—æ³•å‚è€ƒ](https://en.wikipedia.org/wiki/Recurrence_quantification_analysis)

---

**ç»´æŠ¤å›¢é˜Ÿ**: çœ¼åŠ¨æ•°æ®åˆ†æç³»ç»Ÿå¼€å‘å›¢é˜Ÿ  
**æœ€åæ›´æ–°**: 2025å¹´1æœˆ28æ—¥  
**æ–‡æ¡£ç‰ˆæœ¬**: v1.0.0 