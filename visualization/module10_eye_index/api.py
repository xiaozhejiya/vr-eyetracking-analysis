"""
æ¨¡å—10 Eye-Index ç»¼åˆè¯„ä¼° - Flask API Blueprint
æä¾›S_eyeè®¡ç®—ã€æ•°æ®è·å–ã€æŠ¥å‘Šç”Ÿæˆçš„åç«¯æ¥å£
åŒ…å«å­æ¨¡å—10-A: æ•°æ®å‡†å¤‡æ„å»ºå™¨
"""

import os
import json
import pandas as pd
import sys
from pathlib import Path
from flask import Blueprint, request, jsonify, send_file

# æ·»åŠ backendç›®å½•åˆ°Pythonè·¯å¾„
backend_path = Path(__file__).parent.parent.parent / "backend"
if str(backend_path) not in sys.path:
    sys.path.insert(0, str(backend_path))
try:
    from .utils import (
        compute_s_eye, 
        eye_index_report, 
        save_dataset_with_s_eye, 
        save_report,
        EYE_FEATURES,
        MMSE_FEATURES
    )
except ImportError:
    # å°è¯•ç»å¯¹å¯¼å…¥
    from visualization.module10_eye_index.utils import (
        compute_s_eye, 
        eye_index_report, 
        save_dataset_with_s_eye, 
        save_report,
        EYE_FEATURES,
        MMSE_FEATURES
    )

# åˆ›å»ºBlueprint
bp = Blueprint("eye_index", __name__, url_prefix="/api/eye-index")

@bp.route("/run", methods=["POST"])
def run_eye_index():
    """
    æ‰§è¡ŒEye-Indexç»¼åˆè¯„ä¼°è®¡ç®—
    
    Request JSON:
    {
        "config_name": "m2_tau1_eps0.05_lmin2",
        "mode": "equal|pca|custom", 
        "weights": [0.1, 0.1, ...] (å¯é€‰ï¼Œä»…mode=customæ—¶ä½¿ç”¨)
    }
    """
    try:
        data = request.get_json()
        
        # è·å–å‚æ•°
        config_name = data.get("config_name")
        mode = data.get("mode", "equal")
        weights = data.get("weights")
        
        if not config_name:
            return jsonify({
                "success": False,
                "error": "ç¼ºå°‘å¿…è¦å‚æ•°: config_name"
            }), 400
        
        print(f"ğŸš€ å¼€å§‹Eye-Indexè®¡ç®—: {config_name}, æ¨¡å¼: {mode}")
        
        # è¯»å–æ¨¡å—9.1çš„æ•°æ®
        source_file = os.path.join("data", "module9_ml_results", config_name, "train_dataset_latest.csv")
        
        # å¦‚æœæœ€æ–°æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°è¯•æŸ¥æ‰¾å…¶ä»–train_datasetæ–‡ä»¶
        if not os.path.exists(source_file):
            data_dir = os.path.join("data", "module9_ml_results", config_name)
            if os.path.exists(data_dir):
                csv_files = [f for f in os.listdir(data_dir) if f.startswith("train_dataset") and f.endswith(".csv")]
                if csv_files:
                    source_file = os.path.join(data_dir, sorted(csv_files)[-1])  # å–æœ€æ–°çš„
                    print(f"ğŸ“ ä½¿ç”¨æ–‡ä»¶: {sorted(csv_files)[-1]}")
        
        if not os.path.exists(source_file):
            return jsonify({
                "success": False,
                "error": f"æ•°æ®æºæ–‡ä»¶ä¸å­˜åœ¨: {source_file}ã€‚è¯·å…ˆè¿è¡Œæ¨¡å—9.1æ•°æ®é¢„å¤„ç†ã€‚"
            }), 404
        
        # è¯»å–æ•°æ®
        df = pd.read_csv(source_file)
        print(f"ğŸ“Š åŠ è½½æ•°æ®: {len(df)} è¡Œ, {len(df.columns)} åˆ—")
        
        # æ£€æŸ¥å¿…è¦ç‰¹å¾
        available_eye_features = [feat for feat in EYE_FEATURES if feat in df.columns]
        available_mmse_features = [feat for feat in MMSE_FEATURES if feat in df.columns]
        
        print(f"ğŸ‘ï¸ å¯ç”¨çœ¼åŠ¨ç‰¹å¾: {len(available_eye_features)}/{len(EYE_FEATURES)}")
        print(f"ğŸ§  å¯ç”¨MMSEç‰¹å¾: {len(available_mmse_features)}/{len(MMSE_FEATURES)}")
        
        if len(available_eye_features) == 0:
            return jsonify({
                "success": False,
                "error": "æ•°æ®ä¸­ä¸åŒ…å«ä»»ä½•çœ¼åŠ¨ç‰¹å¾ï¼Œè¯·æ£€æŸ¥æ•°æ®æº"
            }), 400
        
        # è®¡ç®—S_eye
        df_with_s_eye = compute_s_eye(df, mode=mode, weights=weights)
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = os.path.join("data", "module10_eye_index", config_name)
        os.makedirs(output_dir, exist_ok=True)
        
        # ä¿å­˜æ•°æ®é›†
        dataset_path = os.path.join(output_dir, "eye_index_dataset.csv")
        save_dataset_with_s_eye(df_with_s_eye, dataset_path)
        
        # ç”ŸæˆæŠ¥å‘Š
        report = eye_index_report(df_with_s_eye)
        report_path = os.path.join(output_dir, "eye_index_report.json")
        save_report(report, report_path)
        
        # è¿”å›æˆåŠŸç»“æœ
        return jsonify({
            "success": True,
            "message": f"Eye-Indexè®¡ç®—å®Œæˆ",
            "stats": report["overall"]["stats"],
            "correlations": report["overall"]["correlations"],
            "metadata": {
                "total_subjects": len(df_with_s_eye),
                "eye_features_count": len(available_eye_features),
                "mmse_features_count": len(available_mmse_features),
                "mode": mode,
                "output_dir": output_dir
            }
        })
        
    except Exception as e:
        print(f"âŒ Eye-Indexè®¡ç®—å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@bp.route("/dataset", methods=["GET"])
def get_dataset():
    """
    è·å–Eye-Indexæ•°æ®é›†CSVæ–‡ä»¶
    
    Query Parameters:
        config: RQAé…ç½®åç§°
    """
    try:
        config_name = request.args.get("config")
        if not config_name:
            return jsonify({"error": "ç¼ºå°‘å‚æ•°: config"}), 400
        
        file_path = os.path.join("data", "module10_eye_index", config_name, "eye_index_dataset.csv")
        
        if not os.path.exists(file_path):
            return jsonify({"error": f"æ•°æ®é›†æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"}), 404
        
        return send_file(file_path, as_attachment=True, download_name=f"eye_index_dataset_{config_name}.csv")
        
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@bp.route("/report", methods=["GET"])
def get_report():
    """
    è·å–Eye-Indexåˆ†ææŠ¥å‘ŠJSON
    
    Query Parameters:
        config: RQAé…ç½®åç§°
    """
    try:
        config_name = request.args.get("config")
        if not config_name:
            return jsonify({"error": "ç¼ºå°‘å‚æ•°: config"}), 400
        
        file_path = os.path.join("data", "module10_eye_index", config_name, "eye_index_report.json")
        
        if not os.path.exists(file_path):
            return jsonify({"error": f"æŠ¥å‘Šæ–‡ä»¶ä¸å­˜åœ¨: {file_path}"}), 404
        
        with open(file_path, 'r', encoding='utf-8') as f:
            report = json.load(f)
        
        return jsonify(report)
        
    except Exception as e:
        return jsonify({"error": str(e)}), 500

@bp.route("/data", methods=["GET"])
def get_data():
    """
    è·å–Eye-Indexæ•°æ®ç”¨äºå‰ç«¯å›¾è¡¨å±•ç¤º
    
    Query Parameters:
        config: RQAé…ç½®åç§°
    """
    try:
        config_name = request.args.get("config")
        if not config_name:
            return jsonify({"error": "ç¼ºå°‘å‚æ•°: config"}), 400
        
        # è¯»å–æ•°æ®é›†
        file_path = os.path.join("data", "module10_eye_index", config_name, "eye_index_dataset.csv")
        
        if not os.path.exists(file_path):
            return jsonify({"error": f"æ•°æ®é›†æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"}), 404
        
        df = pd.read_csv(file_path)
        
        # å‡†å¤‡å‰ç«¯å±•ç¤ºæ•°æ®
        chart_data = {
            "subjects": df["Subject_ID"].tolist() if "Subject_ID" in df.columns else [],
            "s_eye": df["S_eye"].tolist() if "S_eye" in df.columns else [],
            "s_eye_z": df["S_eye_z"].tolist() if "S_eye_z" in df.columns else [],
            "groups": df["Group_Type"].tolist() if "Group_Type" in df.columns else [],
            "mmse_scores": {}
        }
        
        # æ·»åŠ MMSEå­åˆ†æ•°æ•°æ®
        for mmse_feat in MMSE_FEATURES:
            if mmse_feat in df.columns:
                chart_data["mmse_scores"][mmse_feat] = df[mmse_feat].tolist()
        
        # æ·»åŠ ç»„åˆ«ç»Ÿè®¡
        group_stats = {}
        if "Group_Type" in df.columns and "S_eye" in df.columns:
            for group in ["control", "mci", "ad"]:
                group_data = df[df["Group_Type"] == group]["S_eye"]
                if len(group_data) > 0:
                    group_stats[group] = {
                        "values": group_data.tolist(),
                        "mean": float(group_data.mean()),
                        "std": float(group_data.std()),
                        "median": float(group_data.median()),
                        "q1": float(group_data.quantile(0.25)),
                        "q3": float(group_data.quantile(0.75)),
                        "count": int(len(group_data))
                    }
        
        chart_data["group_stats"] = group_stats
        
        return jsonify({
            "success": True,
            "data": chart_data
        })
        
    except Exception as e:
        print(f"âŒ è·å–å›¾è¡¨æ•°æ®å¤±è´¥: {str(e)}")
        return jsonify({"error": str(e)}), 500

@bp.route("/available-configs", methods=["GET"])
def get_available_configs():
    """è·å–å¯ç”¨çš„Eye-Indexé…ç½®åˆ—è¡¨"""
    try:
        base_dir = os.path.join("data", "module10_eye_index")
        configs = []
        
        if os.path.exists(base_dir):
            for item in os.listdir(base_dir):
                item_path = os.path.join(base_dir, item)
                if os.path.isdir(item_path):
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«å¿…è¦æ–‡ä»¶
                    dataset_file = os.path.join(item_path, "eye_index_dataset.csv")
                    report_file = os.path.join(item_path, "eye_index_report.json")
                    
                    config_info = {
                        "name": item,
                        "has_dataset": os.path.exists(dataset_file),
                        "has_report": os.path.exists(report_file)
                    }
                    
                    if config_info["has_dataset"]:
                        # è¯»å–åŸºæœ¬ä¿¡æ¯
                        try:
                            df = pd.read_csv(dataset_file)
                            config_info["subject_count"] = len(df)
                            config_info["has_s_eye"] = "S_eye" in df.columns
                        except:
                            config_info["subject_count"] = 0
                            config_info["has_s_eye"] = False
                    
                    configs.append(config_info)
        
        return jsonify({
            "success": True,
            "configs": configs
        })
        
    except Exception as e:
        return jsonify({"error": str(e)}), 500


# ================= å­æ¨¡å—10-A: æ•°æ®å‡†å¤‡æ„å»ºå™¨API =================

@bp.route("/build-dataset", methods=["POST"])
def build_dataset():
    """
    æ„å»ºç‰¹å¾æ•°æ®é›† (å­æ¨¡å—10-A)
    
    Request JSON:
    {
        "rqa_config": "m2_tau1_eps0.06_lmin2",
        "val_split": 0.2,
        "random_state": 42
    }
    """
    try:
        data = request.get_json()
        rqa_config = data.get("rqa_config")
        val_split = data.get("val_split", 0.2)
        random_state = data.get("random_state", 42)
        
        if not rqa_config:
            return jsonify({"error": "ç¼ºå°‘rqa_configå‚æ•°"}), 400
        
        # å¯¼å…¥æ„å»ºå™¨
        try:
            from m10_data_prep import FeatureBuilder
        except ImportError as e:
            return jsonify({"error": f"æ— æ³•å¯¼å…¥FeatureBuilder: {str(e)}"}), 500
        
        # åˆ›å»ºæ„å»ºå™¨å®ä¾‹
        builder = FeatureBuilder(
            rqa_sig=rqa_config,
            val_split=val_split,
            random_state=random_state
        )
        
        # æ‰§è¡Œæ„å»º
        meta = builder.run_all()
        
        return jsonify({
            "success": True,
            "message": "æ•°æ®é›†æ„å»ºå®Œæˆ",
            "meta": meta,
            "output_dir": str(builder.output_dir)
        })
        
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500


@bp.route("/check-prerequisites", methods=["POST"])
def check_prerequisites():
    """
    æ£€æŸ¥æ„å»ºæ•°æ®é›†çš„å‰ç½®æ¡ä»¶
    
    Request JSON:
    {
        "rqa_config": "m2_tau1_eps0.06_lmin2"
    }
    """
    try:
        data = request.get_json()
        rqa_config = data.get("rqa_config")
        
        if not rqa_config:
            return jsonify({"error": "ç¼ºå°‘rqa_configå‚æ•°"}), 400
        
        # å¯¼å…¥æ„å»ºå™¨
        try:
            from m10_data_prep import FeatureBuilder
        except ImportError as e:
            return jsonify({"error": f"æ— æ³•å¯¼å…¥FeatureBuilder: {str(e)}"}), 500
        
        # åˆ›å»ºæ„å»ºå™¨å®ä¾‹å¹¶æ£€æŸ¥å‰ç½®æ¡ä»¶
        builder = FeatureBuilder(rqa_sig=rqa_config)
        prereq_report = builder.check_prerequisites()
        
        return jsonify({
            "success": True,
            "report": prereq_report
        })
        
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500


@bp.route("/dataset-status", methods=["GET"])
def dataset_status():
    """
    è·å–å·²æ„å»ºæ•°æ®é›†çš„çŠ¶æ€ä¿¡æ¯
    """
    try:
        # å¯¼å…¥è®¾ç½®
        try:
            from m10_data_prep.settings import MODULE10_ROOT, FILE_PATTERNS
        except ImportError as e:
            return jsonify({"error": f"æ— æ³•å¯¼å…¥è®¾ç½®: {str(e)}"}), 500
        
        datasets = []
        
        # æ‰«ææ¨¡å—10è¾“å‡ºç›®å½•
        if MODULE10_ROOT.exists():
            for config_dir in MODULE10_ROOT.iterdir():
                if config_dir.is_dir():
                    meta_file = config_dir / FILE_PATTERNS["module10_meta"]
                    
                    if meta_file.exists():
                        try:
                            with open(meta_file, 'r', encoding='utf-8') as f:
                                meta = json.load(f)
                            
                            # æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                            task_files = {}
                            for task_id in ["Q1", "Q2", "Q3", "Q4", "Q5"]:
                                task_file = config_dir / FILE_PATTERNS["module10_task"].format(task_id=task_id)
                                task_files[task_id] = task_file.exists()
                            
                            dataset_info = {
                                "rqa_sig": meta.get("rqa_sig", config_dir.name),
                                "generated_at": meta.get("generated_at"),
                                "samples": meta.get("samples", {}),
                                "val_split": meta.get("val_split", 0.2),
                                "task_files": task_files,
                                "output_dir": str(config_dir),
                                "total_samples": sum(meta.get("samples", {}).values())
                            }
                            
                            datasets.append(dataset_info)
                            
                        except Exception as e:
                            # è·³è¿‡æœ‰é—®é¢˜çš„é…ç½®
                            continue
        
        return jsonify({
            "success": True,
            "datasets": datasets
        })
        
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500


# æ³¨å†ŒBlueprintçš„å‡½æ•°
def register_eye_index_routes(app):
    """æ³¨å†ŒEye-Indexç›¸å…³çš„APIè·¯ç”±"""
    app.register_blueprint(bp)
    print("âœ… æ¨¡å—10 Eye-Index APIè·¯ç”±å·²æ³¨å†Œ")