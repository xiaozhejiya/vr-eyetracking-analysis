"""
æ¨¡å—10 Eye-Index ç»¼åˆè¯„ä¼° - æ ¸å¿ƒå·¥å…·å‡½æ•°
å®ç°ç»¼åˆçœ¼åŠ¨ç³»æ•° S_eye è®¡ç®—ã€ç»Ÿè®¡åˆ†æã€æŠ¥å‘Šç”Ÿæˆ
"""

import numpy as np
import pandas as pd
import json
import os
from datetime import datetime
from sklearn.decomposition import PCA
from scipy.stats import pearsonr
import warnings
warnings.filterwarnings('ignore')

# å®šä¹‰10ä¸ªæ ¸å¿ƒçœ¼åŠ¨ç‰¹å¾ï¼ˆä¸ç”¨æˆ·è§„èŒƒä¸€è‡´ï¼‰
EYE_FEATURES = [
    'game_duration', 'kw_roi_time', 'inst_roi_time', 'bg_roi_time',
    'rr_1d', 'det_1d', 'ent_1d', 'rr_2d', 'det_2d', 'ent_2d'
]

# MMSEå­åˆ†æ•°åˆ—å
MMSE_FEATURES = [
    'Q1_subscore', 'Q2_subscore', 'Q3_subscore', 'Q4_subscore', 'Q5_subscore'
]

def compute_s_eye(df, mode="equal", weights=None):
    """
    è®¡ç®—ç»¼åˆçœ¼åŠ¨ç³»æ•° S_eye
    
    Args:
        df: åŒ…å«çœ¼åŠ¨ç‰¹å¾çš„DataFrame
        mode: è®¡ç®—æ¨¡å¼ ("equal", "pca", "custom")
        weights: è‡ªå®šä¹‰æƒé‡åˆ—è¡¨ï¼ˆä»…åœ¨mode="custom"æ—¶ä½¿ç”¨ï¼‰
    
    Returns:
        DataFrame: æ·»åŠ äº†S_eyeå’ŒS_eye_zåˆ—çš„æ•°æ®æ¡†
    """
    
    # æ£€æŸ¥å¿…è¦ç‰¹å¾æ˜¯å¦å­˜åœ¨
    available_features = []
    for feat in EYE_FEATURES:
        if feat in df.columns:
            available_features.append(feat)
    
    if len(available_features) == 0:
        raise ValueError("æ•°æ®æ¡†ä¸­ä¸åŒ…å«ä»»ä½•çœ¼åŠ¨ç‰¹å¾")
    
    print(f"ğŸ“Š ä½¿ç”¨ç‰¹å¾æ•°é‡: {len(available_features)}/{len(EYE_FEATURES)}")
    print(f"ğŸ“‹ å¯ç”¨ç‰¹å¾: {available_features}")
    
    # æå–ç‰¹å¾çŸ©é˜µï¼ˆå¡«å……ç¼ºå¤±å€¼ï¼‰
    feats = df[available_features].fillna(0).values
    
    if mode == "equal":
        # ç­‰æƒå¹³å‡
        s_eye = feats.mean(axis=1)
        print("ğŸ§® è®¡ç®—æ¨¡å¼: ç­‰æƒå¹³å‡")
        
    elif mode == "pca":
        # PCAç¬¬ä¸€ä¸»æˆåˆ†
        if feats.shape[1] < 2:
            print("âš ï¸ ç‰¹å¾æ•°é‡ä¸è¶³ï¼Œå›é€€åˆ°ç­‰æƒå¹³å‡")
            s_eye = feats.mean(axis=1)
        else:
            pca = PCA(n_components=1)
            pcs = pca.fit_transform(feats)
            # å½’ä¸€åŒ–åˆ°[0,1]
            s_eye = (pcs.flatten() - pcs.min()) / (pcs.max() - pcs.min())
            print(f"ğŸ§® è®¡ç®—æ¨¡å¼: PCAç¬¬ä¸€ä¸»æˆåˆ† (è§£é‡Šæ–¹å·®: {pca.explained_variance_ratio_[0]:.3f})")
            
    elif mode == "custom":
        # è‡ªå®šä¹‰æƒé‡
        if weights is None or len(weights) != len(available_features):
            print("âš ï¸ æƒé‡å‚æ•°æ— æ•ˆï¼Œå›é€€åˆ°ç­‰æƒå¹³å‡")
            s_eye = feats.mean(axis=1)
        else:
            w = np.asarray(weights, dtype=float)
            w = w / w.sum()  # å½’ä¸€åŒ–æƒé‡
            s_eye = (feats * w).sum(axis=1)
            print(f"ğŸ§® è®¡ç®—æ¨¡å¼: è‡ªå®šä¹‰æƒé‡ {w.round(3)}")
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„è®¡ç®—æ¨¡å¼: {mode}")
    
    # æ·»åŠ åˆ°æ•°æ®æ¡†
    df = df.copy()
    df['S_eye'] = s_eye
    
    # è®¡ç®—Zåˆ†æ•°ï¼ˆæ ‡å‡†åŒ–ï¼‰
    if s_eye.std() > 0:
        df['S_eye_z'] = (s_eye - s_eye.mean()) / s_eye.std()
    else:
        df['S_eye_z'] = 0
    
    print(f"âœ… S_eyeè®¡ç®—å®Œæˆ: èŒƒå›´ [{s_eye.min():.3f}, {s_eye.max():.3f}], å‡å€¼ {s_eye.mean():.3f}")
    
    return df

def generate_statistics(df):
    """ç”ŸæˆS_eyeçš„æè¿°æ€§ç»Ÿè®¡"""
    s_eye = df['S_eye']
    
    stats = {
        'count': int(len(s_eye)),
        'mean': float(s_eye.mean()),
        'std': float(s_eye.std()),
        'min': float(s_eye.min()),
        'max': float(s_eye.max()),
        'q25': float(s_eye.quantile(0.25)),
        'q50': float(s_eye.quantile(0.50)),
        'q75': float(s_eye.quantile(0.75))
    }
    
    return stats

def generate_group_stats(df):
    """æŒ‰ç»„åˆ«ç”Ÿæˆç»Ÿè®¡"""
    group_stats = {}
    
    if 'Group_Type' in df.columns:
        for group in ['control', 'mci', 'ad']:
            group_data = df[df['Group_Type'] == group]
            if len(group_data) > 0:
                group_stats[group] = generate_statistics(group_data)
    
    return group_stats

def calculate_correlations(df):
    """è®¡ç®—S_eyeä¸MMSEå­åˆ†æ•°çš„ç›¸å…³æ€§"""
    correlations = {}
    
    if 'S_eye' not in df.columns:
        return correlations
    
    s_eye = df['S_eye']
    
    for mmse_feat in MMSE_FEATURES:
        if mmse_feat in df.columns:
            mmse_scores = df[mmse_feat].dropna()
            s_eye_aligned = s_eye[mmse_scores.index]
            
            if len(mmse_scores) > 1 and len(s_eye_aligned) > 1:
                try:
                    r, p = pearsonr(s_eye_aligned, mmse_scores)
                    correlations[mmse_feat] = {
                        'r': float(r),
                        'p': float(p),
                        'n': int(len(mmse_scores)),
                        'significant': p < 0.05
                    }
                except:
                    correlations[mmse_feat] = {
                        'r': 0.0,
                        'p': 1.0,
                        'n': 0,
                        'significant': False
                    }
    
    return correlations

def eye_index_report(df):
    """ç”Ÿæˆç»¼åˆEye-IndexæŠ¥å‘Š"""
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    report = {
        'metadata': {
            'timestamp': timestamp,
            'total_subjects': int(len(df)),
            'eye_features_used': [feat for feat in EYE_FEATURES if feat in df.columns],
            'mmse_features_available': [feat for feat in MMSE_FEATURES if feat in df.columns]
        },
        'overall': {
            'stats': generate_statistics(df) if 'S_eye' in df.columns else {},
            'correlations': calculate_correlations(df)
        },
        'by_group': generate_group_stats(df) if 'S_eye' in df.columns else {},
        'interpretation': generate_interpretation(df) if 'S_eye' in df.columns else ""
    }
    
    return report

def generate_interpretation(df):
    """ç”Ÿæˆè§£é‡Šæ€§æ–‡æœ¬"""
    
    if 'S_eye' not in df.columns:
        return "S_eyeæœªè®¡ç®—"
    
    stats = generate_statistics(df)
    group_stats = generate_group_stats(df)
    correlations = calculate_correlations(df)
    
    interpretation = []
    
    # æ•´ä½“åˆ†å¸ƒè§£é‡Š
    interpretation.append(f"**ç»¼åˆçœ¼åŠ¨ç³»æ•° (S_eye) åˆ†ææŠ¥å‘Š**")
    interpretation.append(f"")
    interpretation.append(f"**æ€»ä½“åˆ†å¸ƒ**ï¼š")
    interpretation.append(f"- æ ·æœ¬æ•°é‡ï¼š{stats['count']} åå—è¯•è€…")
    interpretation.append(f"- å‡å€¼Â±æ ‡å‡†å·®ï¼š{stats['mean']:.3f} Â± {stats['std']:.3f}")
    interpretation.append(f"- ä¸­ä½æ•° [IQR]ï¼š{stats['q50']:.3f} [{stats['q25']:.3f}-{stats['q75']:.3f}]")
    interpretation.append(f"")
    
    # ç»„åˆ«å¯¹æ¯”
    if group_stats:
        interpretation.append(f"**ç»„åˆ«å¯¹æ¯”**ï¼š")
        for group_name in ['control', 'mci', 'ad']:
            group_cn = {'control': 'æ§åˆ¶ç»„', 'mci': 'MCIç»„', 'ad': 'ADç»„'}[group_name]
            if group_name in group_stats:
                gstats = group_stats[group_name]
                interpretation.append(f"- {group_cn}ï¼š{gstats['mean']:.3f} Â± {gstats['std']:.3f} (n={gstats['count']})")
        interpretation.append(f"")
    
    # ç›¸å…³æ€§åˆ†æ
    if correlations:
        interpretation.append(f"**ä¸MMSEè®¤çŸ¥è¯„ä¼°çš„ç›¸å…³æ€§**ï¼š")
        for mmse_name, corr_data in correlations.items():
            task_cn = {
                'Q1_subscore': 'Q1(æ—¶é—´å®šå‘)',
                'Q2_subscore': 'Q2(ç©ºé—´å®šå‘)', 
                'Q3_subscore': 'Q3(å³åˆ»è®°å¿†)',
                'Q4_subscore': 'Q4(æ³¨æ„åŠ›è®¡ç®—)',
                'Q5_subscore': 'Q5(å»¶è¿Ÿå›å¿†)'
            }.get(mmse_name, mmse_name)
            
            sig_mark = "**" if corr_data['significant'] else ""
            interpretation.append(f"- {task_cn}ï¼šr = {corr_data['r']:.3f}{sig_mark} (n={corr_data['n']})")
        interpretation.append(f"")
    
    # ä¸´åºŠæ„ä¹‰è§£é‡Š
    interpretation.append(f"**ä¸´åºŠæ„ä¹‰**ï¼š")
    interpretation.append(f"S_eye åæ˜ å—è¯•è€…åœ¨VRè®¤çŸ¥ä»»åŠ¡ä¸­çš„ç»¼åˆçœ¼åŠ¨è¡¨ç°ã€‚æ•°å€¼è¶Šé«˜è¡¨ç¤ºï¼š")
    interpretation.append(f"- æ¸¸æˆå®Œæˆæ—¶é—´æ›´çŸ­ï¼ˆæ•ˆç‡æ›´é«˜ï¼‰")
    interpretation.append(f"- ROIå…³æ³¨æ—¶é—´æ›´åˆç†ï¼ˆæ³¨æ„åŠ›æ›´é›†ä¸­ï¼‰")  
    interpretation.append(f"- RQAå‚æ•°æ›´ä¼˜ï¼ˆçœ¼åŠ¨æ¨¡å¼æ›´ç¨³å®šï¼‰")
    interpretation.append(f"")
    interpretation.append(f"å¯ä½œä¸ºä¼ ç»ŸMMSEè¯„ä¼°çš„å®¢è§‚è¡¥å……æŒ‡æ ‡ï¼Œç”¨äºè®¤çŸ¥åŠŸèƒ½çš„é‡åŒ–è¯„ä¼°ã€‚")
    
    return "\n".join(interpretation)

def save_dataset_with_s_eye(df, output_path):
    """ä¿å­˜å¸¦æœ‰S_eyeçš„æ•°æ®é›†"""
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    df.to_csv(output_path, index=False)
    print(f"ğŸ’¾ æ•°æ®é›†å·²ä¿å­˜: {output_path}")

def save_report(report, output_path):
    """ä¿å­˜JSONæŠ¥å‘Š"""
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    print(f"ğŸ“„ æŠ¥å‘Šå·²ä¿å­˜: {output_path}")