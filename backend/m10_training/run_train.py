#!/usr/bin/env python3
"""
æ¨¡å—10-B: CLIè®­ç»ƒå…¥å£
====================================

å‘½ä»¤è¡Œç•Œé¢ï¼Œç”¨äºå¯åŠ¨å•ä¸ªQä»»åŠ¡çš„æ¨¡å‹è®­ç»ƒã€‚

ä½¿ç”¨ç¤ºä¾‹:
    python -m m10_training.run_train --rqa_config m2_tau1_eps0.055_lmin2 --q_tag Q1
    python -m m10_training.run_train --rqa_config m2_tau1_eps0.055_lmin2 --q_tag Q3 --override '{"training":{"epochs":600}}'
"""

import argparse
import json
import sys
import logging
from pathlib import Path
from typing import Dict, Any, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from backend.m10_training.trainer import create_trainer_from_config, deep_update


def setup_logging(verbose: bool = False):
    """
    è®¾ç½®æ—¥å¿—é…ç½®
    
    Args:
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—
    """
    level = logging.DEBUG if verbose else logging.INFO
    
    logging.basicConfig(
        level=level,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    
    # è®¾ç½®ç¬¬ä¸‰æ–¹åº“çš„æ—¥å¿—çº§åˆ«
    logging.getLogger('matplotlib').setLevel(logging.WARNING)
    logging.getLogger('PIL').setLevel(logging.WARNING)


def parse_arguments() -> argparse.Namespace:
    """
    è§£æå‘½ä»¤è¡Œå‚æ•°
    
    Returns:
        è§£æåçš„å‚æ•°å‘½åç©ºé—´
    """
    parser = argparse.ArgumentParser(
        description="æ¨¡å—10-B: PyTorch MLPè®­ç»ƒå™¨",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # åŸºç¡€è®­ç»ƒ
  python -m m10_training.run_train --rqa_config m2_tau1_eps0.055_lmin2 --q_tag Q1
  
  # è‡ªå®šä¹‰å‚æ•°
  python -m m10_training.run_train \\
    --rqa_config m2_tau1_eps0.055_lmin2 \\
    --q_tag Q3 \\
    --override '{"training":{"epochs":600,"lr":0.001},"arch":{"h1":64}}'
  
  # æŒ‡å®šGPU
  python -m m10_training.run_train \\
    --rqa_config m2_tau1_eps0.055_lmin2 \\
    --q_tag Q1 \\
    --device cuda:0
  
  # è¯¦ç»†è¾“å‡º
  python -m m10_training.run_train \\
    --rqa_config m2_tau1_eps0.055_lmin2 \\
    --q_tag Q1 \\
    --verbose
        """
    )
    
    # å¿…éœ€å‚æ•°
    parser.add_argument(
        "--rqa_config",
        type=str,
        required=True,
        help="RQAé…ç½®ç­¾åï¼Œå¦‚ m2_tau1_eps0.055_lmin2"
    )
    
    parser.add_argument(
        "--q_tag",
        type=str,
        required=True,
        choices=["Q1", "Q2", "Q3", "Q4", "Q5"],
        help="MMSEå­ä»»åŠ¡æ ‡ç­¾"
    )
    
    # å¯é€‰å‚æ•°
    parser.add_argument(
        "--config",
        type=str,
        default=None,
        help="é…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: backend/m10_training/config.yaml)"
    )
    
    parser.add_argument(
        "--override",
        type=str,
        default=None,
        help="JSONå­—ç¬¦ä¸²ï¼Œç”¨äºè¦†ç›–é…ç½®æ–‡ä»¶ä¸­çš„å‚æ•°"
    )
    
    parser.add_argument(
        "--device",
        type=str,
        default=None,
        help="è®¡ç®—è®¾å¤‡ (cpu, cuda, cuda:0 ç­‰)"
    )
    
    parser.add_argument(
        "--data_root",
        type=str,
        default="data/module10_datasets",
        help="æ•°æ®é›†æ ¹ç›®å½•"
    )
    
    parser.add_argument(
        "--output_dir",
        type=str,
        default=None,
        help="è¾“å‡ºç›®å½• (é»˜è®¤ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„è®¾ç½®)"
    )
    
    parser.add_argument(
        "--verbose",
        action="store_true",
        help="æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—"
    )
    
    parser.add_argument(
        "--dry_run",
        action="store_true",
        help="ä»…éªŒè¯é…ç½®ï¼Œä¸å®é™…è®­ç»ƒ"
    )
    
    return parser.parse_args()


def validate_arguments(args: argparse.Namespace) -> bool:
    """
    éªŒè¯å‘½ä»¤è¡Œå‚æ•°
    
    Args:
        args: è§£æåçš„å‚æ•°
        
    Returns:
        æ˜¯å¦éªŒè¯é€šè¿‡
    """
    errors = []
    
    # æ£€æŸ¥æ•°æ®é›†æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    data_path = Path(args.data_root) / args.rqa_config / f"{args.q_tag}.npz"
    if not data_path.exists():
        errors.append(f"æ•°æ®é›†æ–‡ä»¶ä¸å­˜åœ¨: {data_path}")
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if args.config:
        config_path = Path(args.config)
        if not config_path.exists():
            errors.append(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
    
    # éªŒè¯override JSONæ ¼å¼
    if args.override:
        try:
            json.loads(args.override)
        except json.JSONDecodeError as e:
            errors.append(f"overrideå‚æ•°JSONæ ¼å¼é”™è¯¯: {str(e)}")
    
    # æ£€æŸ¥è®¾å¤‡æ ¼å¼
    if args.device and not args.device.startswith(("cpu", "cuda")):
        errors.append(f"æ— æ•ˆçš„è®¾å¤‡æ ¼å¼: {args.device}")
    
    if errors:
        for error in errors:
            print(f"âŒ é”™è¯¯: {error}", file=sys.stderr)
        return False
    
    return True


def load_and_merge_config(args: argparse.Namespace) -> Dict[str, Any]:
    """
    åŠ è½½å¹¶åˆå¹¶é…ç½®
    
    Args:
        args: å‘½ä»¤è¡Œå‚æ•°
        
    Returns:
        æœ€ç»ˆé…ç½®å­—å…¸
    """
    # ç¡®å®šé…ç½®æ–‡ä»¶è·¯å¾„
    if args.config:
        config_path = Path(args.config)
    else:
        config_path = Path(__file__).parent / "config.yaml"
    
    if not config_path.exists():
        raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
    
    # åŠ è½½åŸºç¡€é…ç½®
    import yaml
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # åº”ç”¨å‘½ä»¤è¡Œå‚æ•°è¦†ç›–
    overrides = {}
    
    if args.device:
        overrides["device"] = args.device
    
    if args.output_dir:
        overrides["save_root"] = args.output_dir
        overrides["log_root"] = str(Path(args.output_dir) / "logs")
    
    # åº”ç”¨JSONè¦†ç›–
    if args.override:
        json_overrides = json.loads(args.override)
        overrides = deep_update(overrides, json_overrides)
    
    # åˆå¹¶é…ç½®
    if overrides:
        config = deep_update(config, overrides)
    
    return config


def print_config_summary(config: Dict[str, Any], args: argparse.Namespace):
    """
    æ‰“å°é…ç½®æ‘˜è¦
    
    Args:
        config: é…ç½®å­—å…¸
        args: å‘½ä»¤è¡Œå‚æ•°
    """
    print("=" * 60)
    print("ğŸš€ æ¨¡å—10-B: PyTorch MLPè®­ç»ƒå™¨")
    print("=" * 60)
    print(f"ğŸ“‹ ä»»åŠ¡ä¿¡æ¯:")
    print(f"   RQAé…ç½®: {args.rqa_config}")
    print(f"   Qä»»åŠ¡: {args.q_tag}")
    print(f"   æ•°æ®é›†: {Path(args.data_root) / args.rqa_config / f'{args.q_tag}.npz'}")
    print()
    
    print(f"âš™ï¸  è®­ç»ƒé…ç½®:")
    training = config.get("training", {})
    print(f"   è®¾å¤‡: {config.get('device', 'cpu')}")
    print(f"   æ‰¹å¤§å°: {training.get('batch_size', 16)}")
    print(f"   è½®æ•°: {training.get('epochs', 100)}")
    print(f"   å­¦ä¹ ç‡: {training.get('lr', 1e-3)}")
    print(f"   éªŒè¯é›†æ¯”ä¾‹: {training.get('val_split', 0.2)}")
    print()
    
    print(f"ğŸ—ï¸  æ¨¡å‹æ¶æ„:")
    arch = config.get("arch", {})
    print(f"   è¾“å…¥ç»´åº¦: {arch.get('input_dim', 10)}")
    print(f"   éšè—å±‚1: {arch.get('h1', 32)}")
    print(f"   éšè—å±‚2: {arch.get('h2', 16)}")
    print(f"   Dropout: {arch.get('dropout', 0.25)}")
    print()
    
    print(f"ğŸ“ è¾“å‡ºè·¯å¾„:")
    print(f"   æ¨¡å‹ä¿å­˜: {config.get('save_root', 'models')}")
    print(f"   æ—¥å¿—ä¿å­˜: {config.get('log_root', 'logs')}")
    print("=" * 60)


def main():
    """ä¸»å‡½æ•°"""
    # è§£æå‚æ•°
    args = parse_arguments()
    
    # è®¾ç½®æ—¥å¿—
    setup_logging(args.verbose)
    logger = logging.getLogger(__name__)
    
    try:
        # éªŒè¯å‚æ•°
        if not validate_arguments(args):
            sys.exit(1)
        
        # åŠ è½½é…ç½®
        config = load_and_merge_config(args)
        
        # æ‰“å°é…ç½®æ‘˜è¦
        print_config_summary(config, args)
        
        # ç¡®å®šæ•°æ®é›†è·¯å¾„
        npz_path = Path(args.data_root) / args.rqa_config / f"{args.q_tag}.npz"
        
        if args.dry_run:
            print("âœ… é…ç½®éªŒè¯é€šè¿‡ (dry-runæ¨¡å¼)")
            return
        
        # åˆ›å»ºè®­ç»ƒå™¨
        logger.info("åˆ›å»ºè®­ç»ƒå™¨...")
        trainer = create_trainer_from_config(
            config_path=Path(__file__).parent / "config.yaml",
            q_tag=args.q_tag,
            rqa_sig=args.rqa_config,
            override_config=config
        )
        
        # å¼€å§‹è®­ç»ƒ
        logger.info("å¼€å§‹è®­ç»ƒ...")
        result = trainer.fit(npz_path)
        
        # æ‰“å°ç»“æœ
        if result["success"]:
            print()
            print("ğŸ‰ è®­ç»ƒæˆåŠŸå®Œæˆ!")
            print(f"   è®­ç»ƒè½®æ•°: {result['epochs_trained']}")
            print(f"   æœ€ä½³è½®æ•°: {result['best_epoch']}")
            print(f"   æœ€ä½³éªŒè¯æŸå¤±: {result['best_val_loss']:.6f}")
            print(f"   æ€»ç”¨æ—¶: {result['total_time']:.2f}ç§’")
            print(f"   æ¨¡å‹è·¯å¾„: {result['model_path']}")
            
            # æ‰“å°æœ€ç»ˆæŒ‡æ ‡
            final_metrics = result["final_metrics"]
            print()
            print("ğŸ“Š æœ€ç»ˆè¯„ä¼°æŒ‡æ ‡:")
            for name, value in final_metrics.items():
                print(f"   {name}: {value:.6f}")
            
            print()
            print("âœ… å¯ä»¥ä½¿ç”¨TensorBoardæŸ¥çœ‹è®­ç»ƒè¿‡ç¨‹:")
            print(f"   tensorboard --logdir {config.get('log_root', 'logs')}/{args.rqa_config}/{args.q_tag}")
        else:
            print("âŒ è®­ç»ƒå¤±è´¥")
            sys.exit(1)
    
    except KeyboardInterrupt:
        print("\nâš ï¸ è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        logger.error(f"è®­ç»ƒè¿‡ç¨‹å‡ºé”™: {str(e)}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()