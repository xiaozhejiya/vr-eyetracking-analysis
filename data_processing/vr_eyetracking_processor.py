# -*- coding: utf-8 -*-
"""
VRçœ¼åŠ¨æ•°æ®å¤„ç†å™¨ - æ ¸å¿ƒæ•°æ®é¢„å¤„ç†æ¨¡å—
å°†åŸå§‹TXTæ–‡ä»¶è½¬æ¢ä¸ºé¢„å¤„ç†çš„CSVæ–‡ä»¶
"""
import os
import sys
import re
import math
import numpy as np
import pandas as pd
from tqdm import tqdm
from datetime import datetime
from typing import List, Tuple, Optional, Dict
from scipy import stats

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
from config.config import *

def parse_new_format(content: str) -> List[Dict]:
    """
    è§£ææ–°æ ¼å¼çš„çœ¼åŠ¨æ•°æ®
    
    Args:
        content: åŸå§‹æ–‡ä»¶å†…å®¹
        
    Returns:
        è§£æåçš„æ•°æ®è®°å½•åˆ—è¡¨
    """
    records = []
    lines = content.strip().split('\n')
    
    for line in lines:
        line = line.strip()
        if not line or line.startswith('#'):
            continue
            
        # åŒ¹é…æ•°æ®è¡Œæ ¼å¼: timestamp x y
        match = re.match(r'(\d+(?:\.\d+)?)\s+([0-9.]+)\s+([0-9.]+)', line)
        if match:
            timestamp_str, x_str, y_str = match.groups()
            
            try:
                timestamp = float(timestamp_str)
                x = float(x_str)
                y = float(y_str)
                
                # éªŒè¯åæ ‡èŒƒå›´
                if 0.0 <= x <= 1.0 and 0.0 <= y <= 1.0:
                    records.append({
                        'timestamp': timestamp,
                        'x': x,
                        'y': y
                    })
                    
            except ValueError:
                continue
                
    return records

def preprocess_vr_eyetracking(records: List[Dict], fov_deg: float = 110.0, 
                            velocity_threshold: float = 1000.0, 
                            z_score_threshold: float = 3.0) -> pd.DataFrame:
    """
    é¢„å¤„ç†VRçœ¼åŠ¨æ•°æ®
    
    Args:
        records: åŸå§‹æ•°æ®è®°å½•
        fov_deg: è§†åœºè§’åº¦æ•°
        velocity_threshold: é€Ÿåº¦è¿‡æ»¤é˜ˆå€¼ (deg/s)
        z_score_threshold: Z-scoreè¿‡æ»¤é˜ˆå€¼
        
    Returns:
        é¢„å¤„ç†åçš„DataFrame
    """
    if not records:
        return pd.DataFrame()
        
    # è½¬æ¢ä¸ºDataFrame
    df = pd.DataFrame(records)
    
    if len(df) < 2:
        return df
        
    # æ’åºç¡®ä¿æ—¶é—´é¡ºåº
    df = df.sort_values('timestamp').reset_index(drop=True)
    
    print(f"  XèŒƒå›´: {df['x'].min():.3f} ~ {df['x'].max():.3f}, "
          f"YèŒƒå›´: {df['y'].min():.3f} ~ {df['y'].max():.3f}")
    
    # è®¡ç®—æ—¶é—´å·®
    df['time_diff'] = df['timestamp'].diff().fillna(0) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
    
    print(f"  time_diffèŒƒå›´: {df['time_diff'].min():.2f} ms ~ {df['time_diff'].max():.2f} ms")
    
    # åæ ‡è½¬æ¢ä¸ºè§†åœºè§’åº¦
    half_fov = fov_deg / 2.0
    df['x_deg'] = (df['x'] - 0.5) * fov_deg  # -55 to +55 åº¦
    df['y_deg'] = (df['y'] - 0.5) * fov_deg  # -55 to +55 åº¦
    
    print(f"\n[æ˜ å°„åˆ°è§†åœºè§’] Â±{half_fov}Â°:")
    print(f"  x_deg: {df['x_deg'].min():.3f} to {df['x_deg'].max():.3f}")
    print(f"  y_deg: {df['y_deg'].min():.3f} to {df['y_deg'].max():.3f}")
    
    # è®¡ç®—è§’é€Ÿåº¦
    df['velocity_deg_s'] = 0.0
    
    for i in range(1, len(df)):
        dt = df.iloc[i]['time_diff'] / 1000.0  # è½¬æ¢ä¸ºç§’
        
        if dt > 0:
            dx_deg = df.iloc[i]['x_deg'] - df.iloc[i-1]['x_deg']
            dy_deg = df.iloc[i]['y_deg'] - df.iloc[i-1]['y_deg']
            
            # è®¡ç®—æ¬§å‡ é‡Œå¾—è·ç¦»çš„è§’åº¦å˜åŒ–
            angular_distance = math.sqrt(dx_deg**2 + dy_deg**2)
            velocity = angular_distance / dt
            
            df.iloc[i, df.columns.get_loc('velocity_deg_s')] = velocity
    
    # æ˜¾ç¤ºé€Ÿåº¦ç»Ÿè®¡
    print(f"\n[é€Ÿåº¦ç»Ÿè®¡] velocity_deg_s:")
    print(f"  å¹³å‡é€Ÿåº¦: {df['velocity_deg_s'].mean():.2f} deg/s")
    print(f"  æœ€å¤§é€Ÿåº¦: {df['velocity_deg_s'].max():.2f} deg/s")
    print(f"  æœ€å°é€Ÿåº¦: {df['velocity_deg_s'].min():.2f} deg/s")
    
    # é€Ÿåº¦è¿‡æ»¤
    initial_count = len(df)
    df = df[df['velocity_deg_s'] <= velocity_threshold]
    after_velocity_filter = len(df)
    
    print(f"\né€Ÿåº¦è¿‡æ»¤: {initial_count} -> {after_velocity_filter} è¡Œ (é˜ˆå€¼: {velocity_threshold} deg/s)")
    
    if len(df) < 2:
        return df
        
    # Z-scoreè¿‡æ»¤å¼‚å¸¸å€¼
    velocity_z_scores = np.abs(stats.zscore(df['velocity_deg_s']))
    df = df[velocity_z_scores <= z_score_threshold]
    after_z_score_filter = len(df)
    
    print(f"Z-scoreè¿‡æ»¤: {after_velocity_filter} -> {after_z_score_filter} è¡Œ (é˜ˆå€¼: {z_score_threshold})")
    
    # è®¡ç®—æ‰«è§†é€Ÿåº¦ç»Ÿè®¡
    saccade_velocities = df[df['velocity_deg_s'] > 30]['velocity_deg_s']  # è®¤ä¸º>30 deg/sä¸ºæ‰«è§†
    if len(saccade_velocities) > 0:
        print(f"å¹³å‡æ‰«è§†é€Ÿåº¦: {saccade_velocities.mean():.2f} deg/s")
    
    # é‡æ–°ç´¢å¼•
    df = df.reset_index(drop=True)
    
    return df

def process_txt_file(input_file: str, output_file: str) -> bool:
    """
    å¤„ç†å•ä¸ªTXTæ–‡ä»¶
    
    Args:
        input_file: è¾“å…¥TXTæ–‡ä»¶è·¯å¾„
        output_file: è¾“å‡ºCSVæ–‡ä»¶è·¯å¾„
        
    Returns:
        å¤„ç†æ˜¯å¦æˆåŠŸ
    """
    try:
        # è¯»å–æ–‡ä»¶
        with open(input_file, 'r', encoding=INPUT_ENCODING) as f:
            content = f.read()
        
        # è§£ææ•°æ®
        records = parse_new_format(content)
        print(f"  è§£æåˆ° {len(records)} æ¡è®°å½•.")
        
        if not records:
            print("  âš ï¸  æœªæ‰¾åˆ°æœ‰æ•ˆæ•°æ®")
            return False
            
        # é¢„å¤„ç†æ•°æ®
        df = preprocess_vr_eyetracking(
            records, 
            fov_deg=FOV_DEGREE,
            velocity_threshold=VELOCITY_THRESHOLD,
            z_score_threshold=STATISTICS_CONFIG['z_score_threshold']
        )
        
        if df.empty:
            print("  âš ï¸  é¢„å¤„ç†åæ•°æ®ä¸ºç©º")
            return False
        
        # æ·»åŠ æ—¶é—´æ ¡å‡†æ‰€éœ€çš„millisecondsåˆ—
        # æ£€æŸ¥timestampåˆ—æ˜¯å¦åŒ…å«å¤§çš„æ¯«ç§’å€¼ï¼ˆåŸå§‹æ ¼å¼ï¼‰æˆ–å°çš„ç›¸å¯¹ç§’å€¼ï¼ˆæ–°æ ¼å¼ï¼‰
        if 'timestamp' in df.columns:
            max_timestamp = df['timestamp'].max()
            if max_timestamp < 10000:  # å¦‚æœæœ€å¤§å€¼å°äº10000ï¼Œè®¤ä¸ºæ˜¯ç›¸å¯¹ç§’å€¼
                print("  ğŸ• æ£€æµ‹åˆ°ç›¸å¯¹æ—¶é—´æˆ³ï¼Œè½¬æ¢ä¸ºæ¯«ç§’æ—¶é—´æˆ³")
                import time
                current_time_ms = int(time.time() * 1000)  # å½“å‰æ—¶é—´çš„æ¯«ç§’æ—¶é—´æˆ³
                df['milliseconds'] = current_time_ms + (df['timestamp'] * 1000).astype(int)
            else:
                print("  ğŸ• æ£€æµ‹åˆ°æ¯«ç§’æ—¶é—´æˆ³ï¼Œç›´æ¥ä½¿ç”¨")
                df['milliseconds'] = df['timestamp'].astype(int)
        else:
            print("  âš ï¸  æœªæ‰¾åˆ°timestampåˆ—ï¼Œåˆ›å»ºé»˜è®¤millisecondsåˆ—")
            import time
            current_time_ms = int(time.time() * 1000)
            df['milliseconds'] = current_time_ms + (df.index * 100)  # å‡è®¾100msé—´éš”
        
        print(f"  ğŸ“‹ æœ€ç»ˆåˆ—ç»“æ„: {list(df.columns)}")
        print(f"  ğŸ• millisecondsèŒƒå›´: {df['milliseconds'].min()} ~ {df['milliseconds'].max()}")
        
        # ä¿å­˜ç»“æœ
        df.to_csv(output_file, index=False, encoding=OUTPUT_ENCODING)
        print(f"\næœ€ç»ˆè®°å½•æ•°= {len(df)}")
        print(f"  => å·²ä¿å­˜: {output_file}")
        
        return True
        
    except Exception as e:
        print(f"  âŒ å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return False

def process_directory(input_dir: str, output_dir: str, 
                     file_prefix: str = "", file_suffix: str = "_preprocessed") -> Dict[str, int]:
    """
    æ‰¹é‡å¤„ç†ç›®å½•ä¸­çš„TXTæ–‡ä»¶
    
    Args:
        input_dir: è¾“å…¥ç›®å½•
        output_dir: è¾“å‡ºç›®å½•
        file_prefix: è¾“å‡ºæ–‡ä»¶å‰ç¼€
        file_suffix: è¾“å‡ºæ–‡ä»¶åç¼€
        
    Returns:
        å¤„ç†ç»Ÿè®¡ä¿¡æ¯
    """
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(output_dir, exist_ok=True)
    
    # æŸ¥æ‰¾TXTæ–‡ä»¶
    txt_files = []
    for file in os.listdir(input_dir):
        if file.endswith('.txt'):
            txt_files.append(file)
    
    txt_files.sort()  # æŒ‰æ–‡ä»¶åæ’åº
    
    if not txt_files:
        print(f"âš ï¸  åœ¨ {input_dir} ä¸­æœªæ‰¾åˆ°TXTæ–‡ä»¶")
        return {'total': 0, 'success': 0, 'failed': 0}
    
    print(f"ğŸ”„ å¤„ç†ç›®å½•: {input_dir}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    print(f"ğŸ“„ æ‰¾åˆ° {len(txt_files)} ä¸ªTXTæ–‡ä»¶")
    print("=" * 50)
    
    success_count = 0
    failed_count = 0
    
    # å¤„ç†æ¯ä¸ªæ–‡ä»¶
    for txt_file in tqdm(txt_files, desc="å¤„ç†æ–‡ä»¶"):
        input_path = os.path.join(input_dir, txt_file)
        
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
        base_name = os.path.splitext(txt_file)[0]
        output_filename = f"{file_prefix}{base_name}{file_suffix}.csv"
        output_path = os.path.join(output_dir, output_filename)
        
        print(f"\n=== å¤„ç†: {input_path} ===")
        
        if process_txt_file(input_path, output_path):
            success_count += 1
        else:
            failed_count += 1
    
    print("\n" + "=" * 50)
    print(f"âœ… å¤„ç†å®Œæˆ!")
    print(f"ğŸ“Š æˆåŠŸ: {success_count}, å¤±è´¥: {failed_count}, æ€»è®¡: {len(txt_files)}")
    
    return {
        'total': len(txt_files),
        'success': success_count, 
        'failed': failed_count
    }

def main():
    """ä¸»å‡½æ•° - ç”¨äºæµ‹è¯•å’Œç‹¬ç«‹è¿è¡Œ"""
    if validate_config():
        print("âœ“ Configuration validation passed")
        show_config_summary()
    else:
        print("âœ— Configuration validation failed")
        return
    
    # ç¤ºä¾‹ç”¨æ³•
    print("\nğŸ”„ VRçœ¼åŠ¨æ•°æ®å¤„ç†å™¨")
    print("=" * 50)
    print("ä½¿ç”¨ç¤ºä¾‹:")
    print("from data_processing.vr_eyetracking_processor import process_directory")
    print("process_directory('data/raw', 'data/processed')")

if __name__ == "__main__":
    main() 