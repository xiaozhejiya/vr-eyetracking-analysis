#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç‰¹å¾å½’ä¸€åŒ–å¤„ç†å™¨ - ç”Ÿæˆå½’ä¸€åŒ–ç‰¹å¾æ•°æ®è¡¨æ ¼

æŒ‰ç…§æ•°æ®åº“ä¸‰å¤§èŒƒå¼è®¾è®¡ï¼Œç”Ÿæˆç¬¦åˆè§„èŒƒçš„å½’ä¸€åŒ–æ•°æ®è¡¨æ ¼ï¼š
1. subjects.csv - å—è¯•è€…åŸºæœ¬ä¿¡æ¯
2. tasks.csv - ä»»åŠ¡ä¿¡æ¯
3. mmse_scores.csv - MMSEè¯„åˆ†
4. game_sessions.csv - æ¸¸æˆä¼šè¯ä¿¡æ¯
5. roi_features.csv - ROIç‰¹å¾
6. rqa_features.csv - RQAç‰¹å¾
7. normalized_features_summary.csv - å½’ä¸€åŒ–ç‰¹å¾æ±‡æ€»
"""

import pandas as pd
import numpy as np
import os
import json
from typing import Dict, List, Tuple
import glob
from pathlib import Path
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class FeatureNormalizer:
    """ç‰¹å¾å½’ä¸€åŒ–å¤„ç†å™¨"""
    
    def __init__(self, data_root: str = "data", output_dir: str = "data/normalized_features"):
        self.data_root = data_root
        self.output_dir = output_dir
        self.normalization_config = None
        self.load_normalization_config()
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        Path(self.output_dir).mkdir(parents=True, exist_ok=True)
        
    def load_normalization_config(self):
        """åŠ è½½å½’ä¸€åŒ–é…ç½®"""
        config_file = "analysis_results/data_range_analysis.json"
        if os.path.exists(config_file):
            with open(config_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                self.normalization_config = data.get('normalization_config', {})
        else:
            logger.warning(f"å½’ä¸€åŒ–é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
            self.normalization_config = self._get_default_config()
    
    def _get_default_config(self) -> Dict:
        """è·å–é»˜è®¤å½’ä¸€åŒ–é…ç½®"""
        return {
            'features': {
                'game_duration': {'min_value': 0.0, 'max_value': 180.0},
                'roi_fixation_time': {'min_value': 0.0, 'max_value': 67.23},
                'RR-2D-xy': {'min_value': 0.0096, 'max_value': 0.2422},
                'RR-1D-x': {'min_value': 0.0298, 'max_value': 0.2870},
                'DET-2D-xy': {'min_value': 0.5808, 'max_value': 0.9655},
                'DET-1D-x': {'min_value': 0.5319, 'max_value': 0.9556},
                'ENT-2D-xy': {'min_value': 0.7219, 'max_value': 3.8210},
                'ENT-1D-x': {'min_value': 0.8879, 'max_value': 3.5615}
            }
        }
    
    def normalize_value(self, value: float, feature_name: str) -> float:
        """å½’ä¸€åŒ–å•ä¸ªå€¼"""
        config = self.normalization_config['features'].get(feature_name, {})
        min_val = config.get('min_value', 0.0)
        max_val = config.get('max_value', 1.0)
        
        if max_val == min_val:
            return 0.0
        
        normalized = (value - min_val) / (max_val - min_val)
        return np.clip(normalized, 0.0, 1.0)\n    \n    def extract_subjects_info(self) -> pd.DataFrame:\n        \"\"\"æå–å—è¯•è€…åŸºæœ¬ä¿¡æ¯\"\"\"\n        logger.info(\"ğŸ“Š æå–å—è¯•è€…åŸºæœ¬ä¿¡æ¯...\")\n        \n        subjects = []\n        \n        # æ‰«ææ ¡å‡†æ•°æ®ç›®å½•\n        groups = ['ad_calibrated', 'mci_calibrated', 'control_calibrated']\n        group_mappings = {\n            'ad_calibrated': 'ad',\n            'mci_calibrated': 'mci', \n            'control_calibrated': 'control'\n        }\n        \n        for group_dir in groups:\n            group_path = os.path.join(self.data_root, group_dir)\n            if not os.path.exists(group_path):\n                continue\n                \n            group_type = group_mappings[group_dir]\n            \n            for group_folder in os.listdir(group_path):\n                folder_path = os.path.join(group_path, group_folder)\n                if not os.path.isdir(folder_path):\n                    continue\n                \n                # ä»æ–‡ä»¶å¤¹åæå–ç»„å·\n                if group_type == 'ad':\n                    group_number = group_folder.replace('ad_group_', '')\n                    subject_id = f'ad{group_number.zfill(2)}'\n                elif group_type == 'mci':\n                    group_number = group_folder.replace('mci_group_', '')\n                    subject_id = f'm{group_number.zfill(2)}'\n                else:  # control\n                    group_number = group_folder.replace('control_group_', '')\n                    subject_id = f'n{group_number.zfill(2)}'\n                \n                subjects.append({\n                    'subject_id': subject_id,\n                    'group_type': group_type,\n                    'group_number': int(group_number),\n                    'original_id': subject_id\n                })\n        \n        subjects_df = pd.DataFrame(subjects)\n        subjects_df = subjects_df.sort_values(['group_type', 'group_number'])\n        \n        logger.info(f\"âœ… æå–äº† {len(subjects_df)} ä¸ªå—è¯•è€…ä¿¡æ¯\")\n        return subjects_df\n    \n    def create_tasks_info(self) -> pd.DataFrame:\n        \"\"\"åˆ›å»ºä»»åŠ¡ä¿¡æ¯è¡¨\"\"\"\n        logger.info(\"ğŸ“Š åˆ›å»ºä»»åŠ¡ä¿¡æ¯è¡¨...\")\n        \n        tasks = [\n            {'task_id': 'Q1', 'task_name': 'ç¬¬ä¸€é¢˜', 'max_duration_seconds': 180.0, 'description': 'VR-MMSEä»»åŠ¡1'},\n            {'task_id': 'Q2', 'task_name': 'ç¬¬äºŒé¢˜', 'max_duration_seconds': 180.0, 'description': 'VR-MMSEä»»åŠ¡2'},\n            {'task_id': 'Q3', 'task_name': 'ç¬¬ä¸‰é¢˜', 'max_duration_seconds': 180.0, 'description': 'VR-MMSEä»»åŠ¡3'},\n            {'task_id': 'Q4', 'task_name': 'ç¬¬å››é¢˜', 'max_duration_seconds': 180.0, 'description': 'VR-MMSEä»»åŠ¡4'},\n            {'task_id': 'Q5', 'task_name': 'ç¬¬äº”é¢˜', 'max_duration_seconds': 180.0, 'description': 'VR-MMSEä»»åŠ¡5'}\n        ]\n        \n        tasks_df = pd.DataFrame(tasks)\n        logger.info(f\"âœ… åˆ›å»ºäº† {len(tasks_df)} ä¸ªä»»åŠ¡è®°å½•\")\n        return tasks_df\n    \n    def extract_mmse_scores(self) -> pd.DataFrame:\n        \"\"\"æå–MMSEè¯„åˆ†\"\"\"\n        logger.info(\"ğŸ“Š æå–MMSEè¯„åˆ†...\")\n        \n        mmse_data = []\n        mmse_files = {\n            'ad': 'MMSE_Score/é˜¿å°”å…¹æµ·é»˜ç—‡ç»„.csv',\n            'mci': 'MMSE_Score/è½»åº¦è®¤çŸ¥éšœç¢ç»„.csv', \n            'control': 'MMSE_Score/æ§åˆ¶ç»„.csv'\n        }\n        \n        for group_type, file_path in mmse_files.items():\n            full_path = os.path.join(self.data_root, file_path)\n            if not os.path.exists(full_path):\n                logger.warning(f\"MMSEæ–‡ä»¶ä¸å­˜åœ¨: {full_path}\")\n                continue\n            \n            try:\n                df = pd.read_csv(full_path)\n                \n                # å¤„ç†åˆ—åï¼ˆå¯èƒ½æœ‰ä¸åŒçš„æ ¼å¼ï¼‰\n                subject_col = None\n                for col in df.columns:\n                    if 'è¯•è€…' in col or 'subject' in col.lower():\n                        subject_col = col\n                        break\n                \n                if not subject_col:\n                    logger.warning(f\"æœªæ‰¾åˆ°å—è¯•è€…åˆ—: {full_path}\")\n                    continue\n                \n                for _, row in df.iterrows():\n                    original_id = str(row[subject_col]).strip()\n                    \n                    # æ ‡å‡†åŒ–subject_id\n                    if group_type == 'ad':\n                        subject_id = f\"ad{original_id.replace('ad', '').zfill(2)}\"\n                    elif group_type == 'mci':\n                        subject_id = f\"m{original_id.replace('M', '').replace('m', '').zfill(2)}\"\n                    else:  # control\n                        subject_id = f\"n{original_id.replace('n', '').zfill(2)}\"\n                    \n                    # VR-MMSEæ€»åˆ†ï¼ˆåŸºäºå„é¡¹å¾—åˆ†æ±‚å’Œï¼‰\n                    vr_mmse_score = 0\n                    score_columns = [col for col in df.columns if col != subject_col]\n                    \n                    orientation_time = 0\n                    orientation_place = 0\n                    immediate_memory = 0\n                    attention_calculation = 0\n                    delayed_recall = 0\n                    \n                    # æ˜ å°„å„é¡¹å¾—åˆ†\n                    for col in score_columns:\n                        val = row[col] if pd.notna(row[col]) else 0\n                        vr_mmse_score += val\n                        \n                        # æ ¹æ®åˆ—ååˆ†ç±»ï¼ˆè¿™éœ€è¦æ ¹æ®å®é™…åˆ—åè°ƒæ•´ï¼‰\n                        if 'å¹´' in col or 'å­£' in col or 'æœˆ' in col or 'æ˜ŸæœŸ' in col or 'æ—¥' in col:\n                            orientation_time += val\n                        elif 'çœ' in col or 'å¸‚' in col or 'åŒº' in col or 'åŒ»é™¢' in col or 'æ¥¼å±‚' in col:\n                            orientation_place += val\n                        elif 'è®°å¿†' in col and ('å³åˆ»' in col or 'ç«‹å³' in col):\n                            immediate_memory += val\n                        elif 'æ³¨æ„' in col or 'è®¡ç®—' in col or 'åºåˆ—' in col:\n                            attention_calculation += val\n                        elif 'å»¶è¿Ÿ' in col or 'å›å¿†' in col:\n                            delayed_recall += val\n                    \n                    # VR-MMSE (21åˆ†) è½¬ æ ‡å‡†MMSE (30åˆ†)\n                    standard_mmse_score = (vr_mmse_score / 21.0) * 30.0\n                    \n                    mmse_data.append({\n                        'subject_id': subject_id,\n                        'vr_mmse_score': int(vr_mmse_score),\n                        'standard_mmse_score': round(standard_mmse_score, 2),\n                        'orientation_time': int(orientation_time),\n                        'orientation_place': int(orientation_place),\n                        'immediate_memory': int(immediate_memory),\n                        'attention_calculation': int(attention_calculation),\n                        'delayed_recall': int(delayed_recall)\n                    })\n                    \n            except Exception as e:\n                logger.error(f\"è¯»å–MMSEæ–‡ä»¶å¤±è´¥ {full_path}: {e}\")\n        \n        mmse_df = pd.DataFrame(mmse_data)\n        logger.info(f\"âœ… æå–äº† {len(mmse_df)} ä¸ªMMSEè¯„åˆ†è®°å½•\")\n        return mmse_df\n    \n    def calculate_game_sessions(self, subjects_df: pd.DataFrame) -> pd.DataFrame:\n        \"\"\"è®¡ç®—æ¸¸æˆä¼šè¯ä¿¡æ¯\"\"\"\n        logger.info(\"ğŸ“Š è®¡ç®—æ¸¸æˆä¼šè¯ä¿¡æ¯...\")\n        \n        sessions = []\n        \n        # æ‰«ææ‰€æœ‰æ ¡å‡†æ•°æ®æ–‡ä»¶\n        groups = ['ad_calibrated', 'mci_calibrated', 'control_calibrated']\n        \n        for group_dir in groups:\n            group_path = os.path.join(self.data_root, group_dir)\n            if not os.path.exists(group_path):\n                continue\n            \n            for group_folder in os.listdir(group_path):\n                folder_path = os.path.join(group_path, group_folder)\n                if not os.path.isdir(folder_path):\n                    continue\n                \n                for file_name in os.listdir(folder_path):\n                    if not file_name.endswith('_preprocessed_calibrated.csv'):\n                        continue\n                    \n                    file_path = os.path.join(folder_path, file_name)\n                    \n                    try:\n                        # ä»æ–‡ä»¶åæå–session_id\n                        session_id = file_name.replace('_preprocessed_calibrated.csv', '')\n                        \n                        # æå–subject_idå’Œtask_id\n                        if session_id.startswith('ad'):\n                            subject_id = session_id[:4]  # ad01, ad02, etc.\n                            task_num = session_id[4:]\n                        elif session_id.startswith('m'):\n                            subject_id = session_id[:3]   # m01, m02, etc.\n                            task_num = session_id[3:]\n                        elif session_id.startswith('n'):\n                            subject_id = session_id[:3]   # n01, n02, etc.\n                            task_num = session_id[3:]\n                        else:\n                            continue\n                        \n                        task_id = f'Q{task_num.replace(\"q\", \"\")}'\n                        \n                        # è¯»å–æ•°æ®æ–‡ä»¶è®¡ç®—æ—¶é•¿\n                        df = pd.read_csv(file_path)\n                        if 'milliseconds' in df.columns and len(df) > 0:\n                            duration_ms = df['milliseconds'].max() - df['milliseconds'].min()\n                            duration_s = duration_ms / 1000.0\n                            \n                            # å½’ä¸€åŒ–æ¸¸æˆæ—¶é•¿\n                            duration_norm = self.normalize_value(duration_s, 'game_duration')\n                            \n                            sessions.append({\n                                'session_id': session_id,\n                                'subject_id': subject_id,\n                                'task_id': task_id,\n                                'game_duration_seconds': round(duration_s, 2),\n                                'game_duration_normalized': round(duration_norm, 4),\n                                'data_points_count': len(df),\n                                'file_path': file_path.replace(self.data_root + os.sep, '')\n                            })\n                            \n                    except Exception as e:\n                        logger.warning(f\"å¤„ç†ä¼šè¯æ–‡ä»¶å¤±è´¥ {file_path}: {e}\")\n        \n        sessions_df = pd.DataFrame(sessions)\n        sessions_df = sessions_df.sort_values(['subject_id', 'task_id'])\n        \n        logger.info(f\"âœ… è®¡ç®—äº† {len(sessions_df)} ä¸ªæ¸¸æˆä¼šè¯\")\n        return sessions_df\n    \n    def aggregate_roi_features(self, sessions_df: pd.DataFrame) -> pd.DataFrame:\n        \"\"\"èšåˆROIç‰¹å¾\"\"\"\n        logger.info(\"ğŸ“Š èšåˆROIç‰¹å¾...\")\n        \n        roi_file = os.path.join(self.data_root, 'event_analysis_results', 'All_ROI_Summary.csv')\n        if not os.path.exists(roi_file):\n            logger.warning(f\"ROIæ–‡ä»¶ä¸å­˜åœ¨: {roi_file}\")\n            return pd.DataFrame()\n        \n        try:\n            roi_df = pd.read_csv(roi_file)\n            \n            roi_features = []\n            \n            # åˆ›å»ºsession_idåˆ°æ—¶é•¿çš„æ˜ å°„\n            session_durations = dict(zip(sessions_df['session_id'], sessions_df['game_duration_seconds']))\n            \n            for session_id in sessions_df['session_id'].unique():\n                session_data = roi_df[roi_df['ADQ_ID'] == session_id]\n                game_duration = session_durations.get(session_id, 1.0)\n                \n                # æŒ‰ROIç±»å‹èšåˆ\n                roi_types = ['KW', 'INST', 'BG']\n                \n                for roi_type in roi_types:\n                    roi_type_data = session_data[session_data['ROI'].str.contains(roi_type, na=False)]\n                    \n                    if len(roi_type_data) > 0:\n                        total_fixation_time = roi_type_data['FixTime'].sum()\n                        total_enter_count = roi_type_data['EnterCount'].sum()\n                        total_regression_count = roi_type_data['RegressionCount'].sum()\n                    else:\n                        total_fixation_time = 0.0\n                        total_enter_count = 0\n                        total_regression_count = 0\n                    \n                    # è®¡ç®—æ—¶é—´å æ¯”\n                    fixation_time_percentage = total_fixation_time / game_duration if game_duration > 0 else 0.0\n                    fixation_time_percentage = min(fixation_time_percentage, 1.0)  # é™åˆ¶åœ¨100%ä»¥å†…\n                    \n                    # å½’ä¸€åŒ–\n                    total_fixation_time_norm = self.normalize_value(total_fixation_time, 'roi_fixation_time')\n                    fixation_time_percentage_norm = fixation_time_percentage  # å·²ç»æ˜¯0-1èŒƒå›´\n                    \n                    roi_features.append({\n                        'session_id': session_id,\n                        'roi_type': roi_type,\n                        'total_fixation_time_seconds': round(total_fixation_time, 3),\n                        'total_fixation_time_normalized': round(total_fixation_time_norm, 4),\n                        'fixation_time_percentage': round(fixation_time_percentage, 4),\n                        'fixation_time_percentage_normalized': round(fixation_time_percentage_norm, 4),\n                        'enter_count': int(total_enter_count),\n                        'regression_count': int(total_regression_count)\n                    })\n            \n            roi_features_df = pd.DataFrame(roi_features)\n            logger.info(f\"âœ… èšåˆäº† {len(roi_features_df)} ä¸ªROIç‰¹å¾è®°å½•\")\n            return roi_features_df\n            \n        except Exception as e:\n            logger.error(f\"èšåˆROIç‰¹å¾å¤±è´¥: {e}\")\n            return pd.DataFrame()\n    \n    def normalize_rqa_features(self, sessions_df: pd.DataFrame) -> pd.DataFrame:\n        \"\"\"å½’ä¸€åŒ–RQAç‰¹å¾\"\"\"\n        logger.info(\"ğŸ“Š å½’ä¸€åŒ–RQAç‰¹å¾...\")\n        \n        rqa_path = os.path.join(self.data_root, 'rqa_pipeline_results', 'm2_tau1_eps0.055_lmin2', 'step1_rqa_calculation')\n        if not os.path.exists(rqa_path):\n            logger.warning(f\"RQAè·¯å¾„ä¸å­˜åœ¨: {rqa_path}\")\n            return pd.DataFrame()\n        \n        try:\n            # è¯»å–æ‰€æœ‰RQAæ–‡ä»¶\n            all_rqa_data = []\n            for group in ['ad', 'control', 'mci']:\n                file_path = os.path.join(rqa_path, f'RQA_1D2D_summary_{group}.csv')\n                if os.path.exists(file_path):\n                    df = pd.read_csv(file_path)\n                    df['group'] = group\n                    all_rqa_data.append(df)\n            \n            if not all_rqa_data:\n                logger.warning(\"æœªæ‰¾åˆ°æœ‰æ•ˆçš„RQAæ•°æ®\")\n                return pd.DataFrame()\n            \n            combined_rqa_df = pd.concat(all_rqa_data, ignore_index=True)\n            \n            rqa_features = []\n            \n            for _, row in combined_rqa_df.iterrows():\n                filename = row['filename']\n                session_id = filename.replace('_preprocessed_calibrated.csv', '')\n                \n                # æ£€æŸ¥session_idæ˜¯å¦åœ¨ä¼šè¯åˆ—è¡¨ä¸­\n                if session_id not in sessions_df['session_id'].values:\n                    continue\n                \n                # åŸå§‹å€¼\n                rr_2d_xy = row.get('RR-2D-xy', 0.0)\n                rr_1d_x = row.get('RR-1D-x', 0.0)\n                det_2d_xy = row.get('DET-2D-xy', 0.0)\n                det_1d_x = row.get('DET-1D-x', 0.0)\n                ent_2d_xy = row.get('ENT-2D-xy', 0.0)\n                ent_1d_x = row.get('ENT-1D-x', 0.0)\n                \n                # å½’ä¸€åŒ–\n                rr_2d_xy_norm = self.normalize_value(rr_2d_xy, 'RR-2D-xy')\n                rr_1d_x_norm = self.normalize_value(rr_1d_x, 'RR-1D-x')\n                det_2d_xy_norm = self.normalize_value(det_2d_xy, 'DET-2D-xy')\n                det_1d_x_norm = self.normalize_value(det_1d_x, 'DET-1D-x')\n                ent_2d_xy_norm = self.normalize_value(ent_2d_xy, 'ENT-2D-xy')\n                ent_1d_x_norm = self.normalize_value(ent_1d_x, 'ENT-1D-x')\n                \n                rqa_features.append({\n                    'session_id': session_id,\n                    'rr_2d_xy': round(rr_2d_xy, 6),\n                    'rr_2d_xy_normalized': round(rr_2d_xy_norm, 4),\n                    'rr_1d_x': round(rr_1d_x, 6),\n                    'rr_1d_x_normalized': round(rr_1d_x_norm, 4),\n                    'det_2d_xy': round(det_2d_xy, 6),\n                    'det_2d_xy_normalized': round(det_2d_xy_norm, 4),\n                    'det_1d_x': round(det_1d_x, 6),\n                    'det_1d_x_normalized': round(det_1d_x_norm, 4),\n                    'ent_2d_xy': round(ent_2d_xy, 6),\n                    'ent_2d_xy_normalized': round(ent_2d_xy_norm, 4),\n                    'ent_1d_x': round(ent_1d_x, 6),\n                    'ent_1d_x_normalized': round(ent_1d_x_norm, 4)\n                })\n            \n            rqa_features_df = pd.DataFrame(rqa_features)\n            logger.info(f\"âœ… å½’ä¸€åŒ–äº† {len(rqa_features_df)} ä¸ªRQAç‰¹å¾è®°å½•\")\n            return rqa_features_df\n            \n        except Exception as e:\n            logger.error(f\"å½’ä¸€åŒ–RQAç‰¹å¾å¤±è´¥: {e}\")\n            return pd.DataFrame()\n    \n    def generate_summary_table(self, sessions_df: pd.DataFrame, roi_features_df: pd.DataFrame, \n                             rqa_features_df: pd.DataFrame) -> pd.DataFrame:\n        \"\"\"ç”Ÿæˆå½’ä¸€åŒ–ç‰¹å¾æ±‡æ€»è¡¨\"\"\"\n        logger.info(\"ğŸ“Š ç”Ÿæˆå½’ä¸€åŒ–ç‰¹å¾æ±‡æ€»è¡¨...\")\n        \n        summary_data = []\n        \n        for _, session in sessions_df.iterrows():\n            session_id = session['session_id']\n            subject_id = session['subject_id']\n            task_id = session['task_id']\n            \n            # ä»subject_idæ¨æ–­group_type\n            if subject_id.startswith('ad'):\n                group_type = 'ad'\n            elif subject_id.startswith('m'):\n                group_type = 'mci'\n            elif subject_id.startswith('n'):\n                group_type = 'control'\n            else:\n                group_type = 'unknown'\n            \n            # åˆå§‹åŒ–æ±‡æ€»è®°å½•\n            summary_record = {\n                'session_id': session_id,\n                'subject_id': subject_id,\n                'task_id': task_id,\n                'group_type': group_type,\n                'game_duration_norm': session['game_duration_normalized']\n            }\n            \n            # æ·»åŠ ROIç‰¹å¾\n            session_roi = roi_features_df[roi_features_df['session_id'] == session_id]\n            for roi_type in ['KW', 'INST', 'BG']:\n                roi_data = session_roi[session_roi['roi_type'] == roi_type]\n                if len(roi_data) > 0:\n                    summary_record[f'roi_{roi_type.lower()}_time_norm'] = roi_data.iloc[0]['total_fixation_time_normalized']\n                    summary_record[f'roi_{roi_type.lower()}_percentage_norm'] = roi_data.iloc[0]['fixation_time_percentage_normalized']\n                else:\n                    summary_record[f'roi_{roi_type.lower()}_time_norm'] = 0.0\n                    summary_record[f'roi_{roi_type.lower()}_percentage_norm'] = 0.0\n            \n            # æ·»åŠ RQAç‰¹å¾\n            session_rqa = rqa_features_df[rqa_features_df['session_id'] == session_id]\n            if len(session_rqa) > 0:\n                rqa_data = session_rqa.iloc[0]\n                summary_record.update({\n                    'rr_2d_norm': rqa_data['rr_2d_xy_normalized'],\n                    'rr_1d_norm': rqa_data['rr_1d_x_normalized'],\n                    'det_2d_norm': rqa_data['det_2d_xy_normalized'],\n                    'det_1d_norm': rqa_data['det_1d_x_normalized'],\n                    'ent_2d_norm': rqa_data['ent_2d_xy_normalized'],\n                    'ent_1d_norm': rqa_data['ent_1d_x_normalized']\n                })\n            else:\n                summary_record.update({\n                    'rr_2d_norm': 0.0,\n                    'rr_1d_norm': 0.0,\n                    'det_2d_norm': 0.0,\n                    'det_1d_norm': 0.0,\n                    'ent_2d_norm': 0.0,\n                    'ent_1d_norm': 0.0\n                })\n            \n            summary_data.append(summary_record)\n        \n        summary_df = pd.DataFrame(summary_data)\n        summary_df = summary_df.sort_values(['group_type', 'subject_id', 'task_id'])\n        \n        logger.info(f\"âœ… ç”Ÿæˆäº† {len(summary_df)} ä¸ªæ±‡æ€»è®°å½•\")\n        return summary_df\n    \n    def save_all_tables(self, subjects_df: pd.DataFrame, tasks_df: pd.DataFrame, \n                       mmse_df: pd.DataFrame, sessions_df: pd.DataFrame,\n                       roi_features_df: pd.DataFrame, rqa_features_df: pd.DataFrame,\n                       summary_df: pd.DataFrame):\n        \"\"\"ä¿å­˜æ‰€æœ‰è¡¨æ ¼\"\"\"\n        logger.info(\"ğŸ’¾ ä¿å­˜æ‰€æœ‰è¡¨æ ¼...\")\n        \n        tables = {\n            'subjects.csv': subjects_df,\n            'tasks.csv': tasks_df,\n            'mmse_scores.csv': mmse_df,\n            'game_sessions.csv': sessions_df,\n            'roi_features.csv': roi_features_df,\n            'rqa_features.csv': rqa_features_df,\n            'normalized_features_summary.csv': summary_df\n        }\n        \n        for filename, df in tables.items():\n            if df is not None and not df.empty:\n                output_path = os.path.join(self.output_dir, filename)\n                df.to_csv(output_path, index=False, encoding='utf-8')\n                logger.info(f\"âœ… ä¿å­˜ {filename}: {len(df)} è¡Œ\")\n            else:\n                logger.warning(f\"âš ï¸ è·³è¿‡ç©ºè¡¨æ ¼: {filename}\")\n    \n    def run_full_normalization(self):\n        \"\"\"è¿è¡Œå®Œæ•´çš„å½’ä¸€åŒ–æµç¨‹\"\"\"\n        logger.info(\"ğŸš€ å¼€å§‹å®Œæ•´çš„ç‰¹å¾å½’ä¸€åŒ–æµç¨‹...\")\n        \n        try:\n            # 1. æå–å—è¯•è€…ä¿¡æ¯\n            subjects_df = self.extract_subjects_info()\n            \n            # 2. åˆ›å»ºä»»åŠ¡ä¿¡æ¯\n            tasks_df = self.create_tasks_info()\n            \n            # 3. æå–MMSEè¯„åˆ†\n            mmse_df = self.extract_mmse_scores()\n            \n            # 4. è®¡ç®—æ¸¸æˆä¼šè¯\n            sessions_df = self.calculate_game_sessions(subjects_df)\n            \n            # 5. èšåˆROIç‰¹å¾\n            roi_features_df = self.aggregate_roi_features(sessions_df)\n            \n            # 6. å½’ä¸€åŒ–RQAç‰¹å¾\n            rqa_features_df = self.normalize_rqa_features(sessions_df)\n            \n            # 7. ç”Ÿæˆæ±‡æ€»è¡¨\n            summary_df = self.generate_summary_table(sessions_df, roi_features_df, rqa_features_df)\n            \n            # 8. ä¿å­˜æ‰€æœ‰è¡¨æ ¼\n            self.save_all_tables(subjects_df, tasks_df, mmse_df, sessions_df,\n                                roi_features_df, rqa_features_df, summary_df)\n            \n            # 9. ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š\n            self.generate_statistics_report(summary_df)\n            \n            logger.info(\"ğŸ‰ å½’ä¸€åŒ–æµç¨‹å®Œæˆï¼\")\n            \n        except Exception as e:\n            logger.error(f\"âŒ å½’ä¸€åŒ–æµç¨‹å¤±è´¥: {e}\")\n            raise\n    \n    def generate_statistics_report(self, summary_df: pd.DataFrame):\n        \"\"\"ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š\"\"\"\n        logger.info(\"ğŸ“Š ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š...\")\n        \n        try:\n            report = []\n            report.append(\"# å½’ä¸€åŒ–ç‰¹å¾ç»Ÿè®¡æŠ¥å‘Š\\n\")\n            report.append(f\"ç”Ÿæˆæ—¶é—´: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n            report.append(f\"æ€»ä¼šè¯æ•°: {len(summary_df)}\\n\")\n            \n            # æŒ‰ç»„ç»Ÿè®¡\n            report.append(\"\\n## æŒ‰å®éªŒç»„ç»Ÿè®¡\\n\")\n            group_stats = summary_df.groupby('group_type').size()\n            for group, count in group_stats.items():\n                report.append(f\"- {group}: {count} ä¸ªä¼šè¯\")\n            \n            # æŒ‰ä»»åŠ¡ç»Ÿè®¡\n            report.append(\"\\n\\n## æŒ‰ä»»åŠ¡ç»Ÿè®¡\\n\")\n            task_stats = summary_df.groupby('task_id').size()\n            for task, count in task_stats.items():\n                report.append(f\"- {task}: {count} ä¸ªä¼šè¯\")\n            \n            # ç‰¹å¾ç»Ÿè®¡\n            report.append(\"\\n\\n## å½’ä¸€åŒ–ç‰¹å¾ç»Ÿè®¡\\n\")\n            numeric_cols = [col for col in summary_df.columns if col.endswith('_norm')]\n            feature_stats = summary_df[numeric_cols].describe()\n            \n            for col in numeric_cols:\n                stats = feature_stats[col]\n                report.append(f\"\\n### {col}\")\n                report.append(f\"- å‡å€¼: {stats['mean']:.4f}\")\n                report.append(f\"- æ ‡å‡†å·®: {stats['std']:.4f}\")\n                report.append(f\"- æœ€å°å€¼: {stats['min']:.4f}\")\n                report.append(f\"- æœ€å¤§å€¼: {stats['max']:.4f}\")\n            \n            # ä¿å­˜æŠ¥å‘Š\n            report_content = \"\\n\".join(report)\n            report_path = os.path.join(self.output_dir, 'statistics_report.md')\n            with open(report_path, 'w', encoding='utf-8') as f:\n                f.write(report_content)\n            \n            logger.info(f\"âœ… ç»Ÿè®¡æŠ¥å‘Šå·²ä¿å­˜: {report_path}\")\n            \n        except Exception as e:\n            logger.error(f\"ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Šå¤±è´¥: {e}\")\n\ndef main():\n    \"\"\"ä¸»å‡½æ•°\"\"\"\n    normalizer = FeatureNormalizer()\n    normalizer.run_full_normalization()\n    \n    print(\"\\nğŸ‰ ç‰¹å¾å½’ä¸€åŒ–å®Œæˆï¼\")\n    print(\"ğŸ“ è¾“å‡ºæ–‡ä»¶ä½ç½®: data/normalized_features/\")\n    print(\"ğŸ“Š ç”Ÿæˆçš„è¡¨æ ¼:\")\n    print(\"   - subjects.csv: å—è¯•è€…åŸºæœ¬ä¿¡æ¯\")\n    print(\"   - tasks.csv: ä»»åŠ¡ä¿¡æ¯\")\n    print(\"   - mmse_scores.csv: MMSEè¯„åˆ†\")\n    print(\"   - game_sessions.csv: æ¸¸æˆä¼šè¯ä¿¡æ¯\")\n    print(\"   - roi_features.csv: ROIç‰¹å¾\")\n    print(\"   - rqa_features.csv: RQAç‰¹å¾\")\n    print(\"   - normalized_features_summary.csv: å½’ä¸€åŒ–ç‰¹å¾æ±‡æ€»\")\n    print(\"   - statistics_report.md: ç»Ÿè®¡æŠ¥å‘Š\")\n\nif __name__ == \"__main__\":\n    main()